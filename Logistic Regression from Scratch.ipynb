{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82334f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f4c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature and label matrix from dataframe\n",
    "def get_numpy_data(dataframe, features, label):\n",
    "    dataframe[\"constant\"] = 1\n",
    "    features = ['constant'] + features\n",
    "    features_dataframe = dataframe[features]\n",
    "    feature_matrix = features_dataframe.as_matrix()\n",
    "    label_sarray = dataframe[label]\n",
    "    label_array = label_sarray.as_matrix()\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b3672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability using sigmoid function\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    predictions = 1/(1 + exp(-score))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Derivative\n",
    "def feature_derivative(errors, feature):\n",
    "    derivative =np.dot(feature, errors)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b54c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Log-likelihood\n",
    "def compute_log_likelihood(feature_matrix, classifications, coefficients):\n",
    "    indicator = (classifications == +1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores)))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression using Gradient Ascent\n",
    "def logistic_regression(feature_matrix, classifications, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    \n",
    "    for i in max_inter:\n",
    "        \n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        indicator = (classifications == +1)\n",
    "        errors = indicator - predictions\n",
    "    \n",
    "        for j in xrange(len(coefficients)):\n",
    "            j_column_feature = feature_matrix[:, j]\n",
    "            derivative = np.dot(j_column_feature, errors)\n",
    "            coefficients = coeffivients + derivative * step_size\n",
    "        \n",
    "        if i <= 100:\n",
    "            log_likelihood = compute_log_likelihood(feature_matrix, classifications, coefficients)\n",
    "            print(\"Round \" + str(i) +\": Log Likelihood = \" + str(log_likelihood))\n",
    "            \n",
    "    return coefficients\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression using Gradient Ascent (100 Iteration)\n",
    "def logistic_regression(feature_matrix, classifications, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    \n",
    "    for i in max_inter:\n",
    "        \n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        indicator = (classifications == +1)\n",
    "        errors = indicator - predictions\n",
    "    \n",
    "        for j in xrange(len(coefficients)):\n",
    "            j_column_feature = feature_matrix[:, j]\n",
    "            derivative = np.dot(j_column_feature, errors)\n",
    "            coefficients = coeffivients + derivative * step_size\n",
    "        \n",
    "        if i <= 100:\n",
    "            log_likelihood = compute_log_likelihood(feature_matrix, classifications, coefficients)\n",
    "            print(\"Round \" + str(i) +\": Log Likelihood = \" + str(log_likelihood))\n",
    "            \n",
    "    return coefficients\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Derivative with L2 Penalty\n",
    "def feature_derivative_with_L2(errors, feature, coefficient, l2_penalty, feature_is_constant):\n",
    "    derivative = np.dot(feature, errors)\n",
    "    \n",
    "    if not feature_is_constant:\n",
    "        derivative = derivative + 2 * l2_penalty * coefficient\n",
    "        \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe3b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
