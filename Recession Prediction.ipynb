{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "119a5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, roc_auc_score, RocCurveDisplay, auc, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef3c8da",
   "metadata": {},
   "source": [
    "To Do List: \n",
    "\n",
    "1. Compare model with and without the cycle indicator using both Penalized Logistic Regression and Gradient Boosting \n",
    "2. Metrics used for Model Comparison: ROC and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e49ccbe",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "92d313df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    features_matrix = dataframe[features].to_numpy()\n",
    "    label_array = dataframe[label].to_numpy()\n",
    "    return  features_matrix, label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "17adb9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(file_path, list_to_drop, test_size, random_state):\n",
    "    \n",
    "    data = pd.read_csv(file_path).drop(list_to_drop, axis = 1)\n",
    "    data[\"spread_derivative\"] = pd.to_numeric(data[\"spread_derivative\"], errors = \"coerce\")\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    feature_list = data.columns.to_list()\n",
    "    feature_list.remove(\"custom_recession_data\")\n",
    "    recession_label = \"custom_recession_data\"\n",
    "\n",
    "    feature_matrix, label_array = get_numpy_data(data, feature_list, recession_label)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(feature_matrix, label_array, test_size = test_size, random_state = random_state)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecd860",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a18e94",
   "metadata": {},
   "source": [
    "1. Recession Data __with__ Volatility Index and Cycle Indicator (Vix/Spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1c9e77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"updated_final_data.csv\"\n",
    "columns_to_drop = [\"Unnamed: 0\", \"date\", \"usrecd\", \"m1sl\", \"m2sl\", \"icsa\", \"mabmm301usm189s\",  \"bogmbase\", \"volume\", \"adj close\"]\n",
    "test_size = 0.3\n",
    "random_state = 11\n",
    "\n",
    "x_train_vix, x_test_vix, y_train_vix, y_test_vix = data_import(file_path, columns_to_drop, test_size, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "710b38ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 15)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af241a4d",
   "metadata": {},
   "source": [
    "2. Recession Data __without__ Volatility Index and Cycle Indicator (Vix/Spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "c3a18d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"updated_final_data.csv\"\n",
    "columns_to_drop = [\"Unnamed: 0\", \"date\", \"usrecd\", \"m1sl\", \"m2sl\", \"icsa\", \"mabmm301usm189s\",  \"bogmbase\", \"volume\", \"adj close\", \"final_vol\", \"cycle_indicator\"]\n",
    "test_size = 0.3\n",
    "random_state = 11\n",
    "\n",
    "x_train, x_test, y_train, y_test = data_import(file_path, columns_to_drop, test_size, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "daa07b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 13)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0647b",
   "metadata": {},
   "source": [
    "# Logistic Regression with L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "31c7ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, QuantileTransformer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline as pipe\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "615a66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Pipe\n",
    "lr_pipe = pipe([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"polynomial\", PolynomialFeatures(1)),\n",
    "    (\"model\", LogisticRegression(random_state = 11))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f5f5d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Grid Search\n",
    "lr_param_grid = [{'model__penalty': ['l1', 'l2'],\n",
    "                   \"model__C\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                   'model__solver': ['liblinear'],\n",
    "                 'polynomial__degree': [1, 2, 3, 4]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4a2ee6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "lr_grid_search = GridSearchCV(estimator=lr_pipe,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba98724b",
   "metadata": {},
   "source": [
    "## Logistic Regression for Data with VIX and Cycle Indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54783934",
   "metadata": {},
   "source": [
    "1. Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d9218c8e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\peter\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>param_model__penalty</th>\n",
       "      <th>param_model__solver</th>\n",
       "      <th>param_polynomial__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 1e-05, 'model__penalty': 'l1', 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 1e-05, 'model__penalty': 'l1', 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 1e-05, 'model__penalty': 'l1', 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023880</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 1e-05, 'model__penalty': 'l1', 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 1e-05, 'model__penalty': 'l2', 'm...</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606897</td>\n",
       "      <td>0.641379</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.734138</td>\n",
       "      <td>0.105124</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 1e-05, 'model__penalty': 'l2', 'm...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537931</td>\n",
       "      <td>0.537931</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>0.584943</td>\n",
       "      <td>0.133747</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 1e-05, 'model__penalty': 'l2', 'm...</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.765517</td>\n",
       "      <td>0.675862</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.742126</td>\n",
       "      <td>0.139698</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.054911</td>\n",
       "      <td>0.006102</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 1e-05, 'model__penalty': 'l2', 'm...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.565517</td>\n",
       "      <td>0.767241</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.745029</td>\n",
       "      <td>0.132903</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 0.0001, 'model__penalty': 'l1', '...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 0.0001, 'model__penalty': 'l1', '...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 0.0001, 'model__penalty': 'l1', '...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.026876</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 0.0001, 'model__penalty': 'l1', '...</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.489339</td>\n",
       "      <td>0.047524</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 0.0001, 'model__penalty': 'l2', '...</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606897</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.629310</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.735029</td>\n",
       "      <td>0.103740</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 0.0001, 'model__penalty': 'l2', '...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565517</td>\n",
       "      <td>0.565517</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>0.611092</td>\n",
       "      <td>0.127585</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.011121</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 0.0001, 'model__penalty': 'l2', '...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.793391</td>\n",
       "      <td>0.137029</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.078171</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 0.0001, 'model__penalty': 'l2', '...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.889655</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.613793</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.781782</td>\n",
       "      <td>0.131584</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 0.001, 'model__penalty': 'l1', 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 0.001, 'model__penalty': 'l1', 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006105</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 0.001, 'model__penalty': 'l1', 'm...</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.501983</td>\n",
       "      <td>0.073935</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.034745</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 0.001, 'model__penalty': 'l1', 'm...</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.296552</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.351724</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.439655</td>\n",
       "      <td>0.381379</td>\n",
       "      <td>0.154685</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 0.001, 'model__penalty': 'l2', 'm...</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634483</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.765517</td>\n",
       "      <td>0.698276</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.761523</td>\n",
       "      <td>0.091605</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 0.001, 'model__penalty': 'l2', 'm...</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.750747</td>\n",
       "      <td>0.128269</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.019371</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 0.001, 'model__penalty': 'l2', 'm...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.806897</td>\n",
       "      <td>0.910345</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833506</td>\n",
       "      <td>0.136350</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.115736</td>\n",
       "      <td>0.019611</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 0.001, 'model__penalty': 'l2', 'm...</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.848276</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.836006</td>\n",
       "      <td>0.127587</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 0.01, 'model__penalty': 'l1', 'mo...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 0.01, 'model__penalty': 'l1', 'mo...</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.558621</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.635201</td>\n",
       "      <td>0.080332</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.014156</td>\n",
       "      <td>0.010383</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 0.01, 'model__penalty': 'l1', 'mo...</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.662069</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.627730</td>\n",
       "      <td>0.085681</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.039623</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 0.01, 'model__penalty': 'l1', 'mo...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0.784483</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.690948</td>\n",
       "      <td>0.116897</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 0.01, 'model__penalty': 'l2', 'mo...</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.917241</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>0.844511</td>\n",
       "      <td>0.086332</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 0.01, 'model__penalty': 'l2', 'mo...</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.910345</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.845057</td>\n",
       "      <td>0.124146</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.028338</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 0.01, 'model__penalty': 'l2', 'mo...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.882787</td>\n",
       "      <td>0.132650</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.177503</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 0.01, 'model__penalty': 'l2', 'mo...</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993103</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 0.1, 'model__penalty': 'l1', 'mod...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765517</td>\n",
       "      <td>0.848276</td>\n",
       "      <td>0.903448</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.858190</td>\n",
       "      <td>0.069613</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 0.1, 'model__penalty': 'l1', 'mod...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.924138</td>\n",
       "      <td>0.868966</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.864655</td>\n",
       "      <td>0.111464</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.012484</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 0.1, 'model__penalty': 'l1', 'mod...</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.868966</td>\n",
       "      <td>0.910345</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838276</td>\n",
       "      <td>0.162176</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.043533</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 0.1, 'model__penalty': 'l1', 'mod...</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889655</td>\n",
       "      <td>0.813793</td>\n",
       "      <td>0.737931</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.848132</td>\n",
       "      <td>0.135948</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 0.1, 'model__penalty': 'l2', 'mod...</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.875862</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.884885</td>\n",
       "      <td>0.097513</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 0.1, 'model__penalty': 'l2', 'mod...</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.917241</td>\n",
       "      <td>0.917241</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909914</td>\n",
       "      <td>0.105261</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.044433</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 0.1, 'model__penalty': 'l2', 'mod...</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.927730</td>\n",
       "      <td>0.107274</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.212566</td>\n",
       "      <td>0.045424</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 0.1, 'model__penalty': 'l2', 'mod...</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 1, 'model__penalty': 'l1', 'model...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.910345</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.906494</td>\n",
       "      <td>0.088491</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 1, 'model__penalty': 'l1', 'model...</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.834483</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911839</td>\n",
       "      <td>0.108655</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.020026</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 1, 'model__penalty': 'l1', 'model...</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.929511</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.057699</td>\n",
       "      <td>0.007739</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 1, 'model__penalty': 'l1', 'model...</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.937931</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928305</td>\n",
       "      <td>0.079797</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 1, 'model__penalty': 'l2', 'model...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848276</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.904943</td>\n",
       "      <td>0.092090</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.012257</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 1, 'model__penalty': 'l2', 'model...</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993103</td>\n",
       "      <td>0.806897</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912845</td>\n",
       "      <td>0.097003</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.075913</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 1, 'model__penalty': 'l2', 'model...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.925144</td>\n",
       "      <td>0.121317</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.318721</td>\n",
       "      <td>0.069048</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 1, 'model__penalty': 'l2', 'model...</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.915086</td>\n",
       "      <td>0.103872</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001520      0.000813         0.000896        0.000300   \n",
       "1        0.001881      0.001043         0.001100        0.000536   \n",
       "2        0.005717      0.000477         0.001708        0.000815   \n",
       "3        0.023880      0.000973         0.002063        0.000379   \n",
       "4        0.001512      0.000449         0.001240        0.000520   \n",
       "5        0.002448      0.000516         0.001045        0.000194   \n",
       "6        0.008767      0.000603         0.001301        0.000458   \n",
       "7        0.054911      0.006102         0.002091        0.000528   \n",
       "8        0.001304      0.000412         0.000891        0.000523   \n",
       "9        0.001901      0.000505         0.001351        0.000466   \n",
       "10       0.006110      0.000903         0.001521        0.000596   \n",
       "11       0.026876      0.002548         0.002002        0.000223   \n",
       "12       0.001651      0.000450         0.001152        0.000503   \n",
       "13       0.002363      0.000396         0.001089        0.000305   \n",
       "14       0.011121      0.000800         0.001657        0.000716   \n",
       "15       0.078171      0.011891         0.001919        0.000517   \n",
       "16       0.001313      0.000401         0.001313        0.000676   \n",
       "17       0.001916      0.000513         0.001100        0.000207   \n",
       "18       0.006105      0.000952         0.001042        0.000157   \n",
       "19       0.034745      0.002428         0.001817        0.000583   \n",
       "20       0.001446      0.000468         0.000849        0.000450   \n",
       "21       0.002815      0.000456         0.001193        0.000470   \n",
       "22       0.019371      0.002005         0.001833        0.000404   \n",
       "23       0.115736      0.019611         0.001915        0.000364   \n",
       "24       0.001508      0.000457         0.001122        0.000252   \n",
       "25       0.002321      0.000426         0.001168        0.000562   \n",
       "26       0.014156      0.010383         0.001505        0.000673   \n",
       "27       0.039623      0.003735         0.001805        0.000467   \n",
       "28       0.001336      0.000430         0.001052        0.000570   \n",
       "29       0.003643      0.000482         0.001199        0.000403   \n",
       "30       0.028338      0.003723         0.001259        0.000601   \n",
       "31       0.177503      0.039129         0.002348        0.000575   \n",
       "32       0.001399      0.000489         0.001542        0.000613   \n",
       "33       0.003145      0.000442         0.001424        0.000451   \n",
       "34       0.012484      0.001436         0.001393        0.000403   \n",
       "35       0.043533      0.001683         0.002100        0.000322   \n",
       "36       0.001326      0.000413         0.000813        0.000368   \n",
       "37       0.005269      0.000593         0.001419        0.000441   \n",
       "38       0.044433      0.003559         0.001691        0.000394   \n",
       "39       0.212566      0.045424         0.001772        0.000397   \n",
       "40       0.002002      0.000744         0.001065        0.000484   \n",
       "41       0.008198      0.000861         0.001004        0.000453   \n",
       "42       0.020026      0.002117         0.001568        0.000555   \n",
       "43       0.057699      0.007739         0.002374        0.000757   \n",
       "44       0.002696      0.000798         0.001805        0.000406   \n",
       "45       0.012257      0.001577         0.002975        0.001091   \n",
       "46       0.075913      0.006365         0.002651        0.000513   \n",
       "47       0.318721      0.069048         0.002904        0.000588   \n",
       "\n",
       "   param_model__C param_model__penalty param_model__solver  \\\n",
       "0         0.00001                   l1           liblinear   \n",
       "1         0.00001                   l1           liblinear   \n",
       "2         0.00001                   l1           liblinear   \n",
       "3         0.00001                   l1           liblinear   \n",
       "4         0.00001                   l2           liblinear   \n",
       "5         0.00001                   l2           liblinear   \n",
       "6         0.00001                   l2           liblinear   \n",
       "7         0.00001                   l2           liblinear   \n",
       "8          0.0001                   l1           liblinear   \n",
       "9          0.0001                   l1           liblinear   \n",
       "10         0.0001                   l1           liblinear   \n",
       "11         0.0001                   l1           liblinear   \n",
       "12         0.0001                   l2           liblinear   \n",
       "13         0.0001                   l2           liblinear   \n",
       "14         0.0001                   l2           liblinear   \n",
       "15         0.0001                   l2           liblinear   \n",
       "16          0.001                   l1           liblinear   \n",
       "17          0.001                   l1           liblinear   \n",
       "18          0.001                   l1           liblinear   \n",
       "19          0.001                   l1           liblinear   \n",
       "20          0.001                   l2           liblinear   \n",
       "21          0.001                   l2           liblinear   \n",
       "22          0.001                   l2           liblinear   \n",
       "23          0.001                   l2           liblinear   \n",
       "24           0.01                   l1           liblinear   \n",
       "25           0.01                   l1           liblinear   \n",
       "26           0.01                   l1           liblinear   \n",
       "27           0.01                   l1           liblinear   \n",
       "28           0.01                   l2           liblinear   \n",
       "29           0.01                   l2           liblinear   \n",
       "30           0.01                   l2           liblinear   \n",
       "31           0.01                   l2           liblinear   \n",
       "32            0.1                   l1           liblinear   \n",
       "33            0.1                   l1           liblinear   \n",
       "34            0.1                   l1           liblinear   \n",
       "35            0.1                   l1           liblinear   \n",
       "36            0.1                   l2           liblinear   \n",
       "37            0.1                   l2           liblinear   \n",
       "38            0.1                   l2           liblinear   \n",
       "39            0.1                   l2           liblinear   \n",
       "40              1                   l1           liblinear   \n",
       "41              1                   l1           liblinear   \n",
       "42              1                   l1           liblinear   \n",
       "43              1                   l1           liblinear   \n",
       "44              1                   l2           liblinear   \n",
       "45              1                   l2           liblinear   \n",
       "46              1                   l2           liblinear   \n",
       "47              1                   l2           liblinear   \n",
       "\n",
       "   param_polynomial__degree  \\\n",
       "0                         1   \n",
       "1                         2   \n",
       "2                         3   \n",
       "3                         4   \n",
       "4                         1   \n",
       "5                         2   \n",
       "6                         3   \n",
       "7                         4   \n",
       "8                         1   \n",
       "9                         2   \n",
       "10                        3   \n",
       "11                        4   \n",
       "12                        1   \n",
       "13                        2   \n",
       "14                        3   \n",
       "15                        4   \n",
       "16                        1   \n",
       "17                        2   \n",
       "18                        3   \n",
       "19                        4   \n",
       "20                        1   \n",
       "21                        2   \n",
       "22                        3   \n",
       "23                        4   \n",
       "24                        1   \n",
       "25                        2   \n",
       "26                        3   \n",
       "27                        4   \n",
       "28                        1   \n",
       "29                        2   \n",
       "30                        3   \n",
       "31                        4   \n",
       "32                        1   \n",
       "33                        2   \n",
       "34                        3   \n",
       "35                        4   \n",
       "36                        1   \n",
       "37                        2   \n",
       "38                        3   \n",
       "39                        4   \n",
       "40                        1   \n",
       "41                        2   \n",
       "42                        3   \n",
       "43                        4   \n",
       "44                        1   \n",
       "45                        2   \n",
       "46                        3   \n",
       "47                        4   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "0   {'model__C': 1e-05, 'model__penalty': 'l1', 'm...           0.500000  ...   \n",
       "1   {'model__C': 1e-05, 'model__penalty': 'l1', 'm...           0.500000  ...   \n",
       "2   {'model__C': 1e-05, 'model__penalty': 'l1', 'm...           0.500000  ...   \n",
       "3   {'model__C': 1e-05, 'model__penalty': 'l1', 'm...           0.500000  ...   \n",
       "4   {'model__C': 1e-05, 'model__penalty': 'l2', 'm...           0.683333  ...   \n",
       "5   {'model__C': 1e-05, 'model__penalty': 'l2', 'm...           0.458333  ...   \n",
       "6   {'model__C': 1e-05, 'model__penalty': 'l2', 'm...           0.541667  ...   \n",
       "7   {'model__C': 1e-05, 'model__penalty': 'l2', 'm...           0.566667  ...   \n",
       "8   {'model__C': 0.0001, 'model__penalty': 'l1', '...           0.500000  ...   \n",
       "9   {'model__C': 0.0001, 'model__penalty': 'l1', '...           0.500000  ...   \n",
       "10  {'model__C': 0.0001, 'model__penalty': 'l1', '...           0.500000  ...   \n",
       "11  {'model__C': 0.0001, 'model__penalty': 'l1', '...           0.541667  ...   \n",
       "12  {'model__C': 0.0001, 'model__penalty': 'l2', '...           0.675000  ...   \n",
       "13  {'model__C': 0.0001, 'model__penalty': 'l2', '...           0.450000  ...   \n",
       "14  {'model__C': 0.0001, 'model__penalty': 'l2', '...           0.600000  ...   \n",
       "15  {'model__C': 0.0001, 'model__penalty': 'l2', '...           0.550000  ...   \n",
       "16  {'model__C': 0.001, 'model__penalty': 'l1', 'm...           0.500000  ...   \n",
       "17  {'model__C': 0.001, 'model__penalty': 'l1', 'm...           0.500000  ...   \n",
       "18  {'model__C': 0.001, 'model__penalty': 'l1', 'm...           0.675000  ...   \n",
       "19  {'model__C': 0.001, 'model__penalty': 'l1', 'm...           0.541667  ...   \n",
       "20  {'model__C': 0.001, 'model__penalty': 'l2', 'm...           0.691667  ...   \n",
       "21  {'model__C': 0.001, 'model__penalty': 'l2', 'm...           0.508333  ...   \n",
       "22  {'model__C': 0.001, 'model__penalty': 'l2', 'm...           0.600000  ...   \n",
       "23  {'model__C': 0.001, 'model__penalty': 'l2', 'm...           0.591667  ...   \n",
       "24  {'model__C': 0.01, 'model__penalty': 'l1', 'mo...           0.500000  ...   \n",
       "25  {'model__C': 0.01, 'model__penalty': 'l1', 'mo...           0.508333  ...   \n",
       "26  {'model__C': 0.01, 'model__penalty': 'l1', 'mo...           0.475000  ...   \n",
       "27  {'model__C': 0.01, 'model__penalty': 'l1', 'mo...           0.550000  ...   \n",
       "28  {'model__C': 0.01, 'model__penalty': 'l2', 'mo...           0.716667  ...   \n",
       "29  {'model__C': 0.01, 'model__penalty': 'l2', 'mo...           0.591667  ...   \n",
       "30  {'model__C': 0.01, 'model__penalty': 'l2', 'mo...           0.650000  ...   \n",
       "31  {'model__C': 0.01, 'model__penalty': 'l2', 'mo...           0.716667  ...   \n",
       "32  {'model__C': 0.1, 'model__penalty': 'l1', 'mod...           0.800000  ...   \n",
       "33  {'model__C': 0.1, 'model__penalty': 'l1', 'mod...           0.566667  ...   \n",
       "34  {'model__C': 0.1, 'model__penalty': 'l1', 'mod...           0.575000  ...   \n",
       "35  {'model__C': 0.1, 'model__penalty': 'l1', 'mod...           0.591667  ...   \n",
       "36  {'model__C': 0.1, 'model__penalty': 'l2', 'mod...           0.716667  ...   \n",
       "37  {'model__C': 0.1, 'model__penalty': 'l2', 'mod...           0.725000  ...   \n",
       "38  {'model__C': 0.1, 'model__penalty': 'l2', 'mod...           0.741667  ...   \n",
       "39  {'model__C': 0.1, 'model__penalty': 'l2', 'mod...           0.758333  ...   \n",
       "40  {'model__C': 1, 'model__penalty': 'l1', 'model...           0.700000  ...   \n",
       "41  {'model__C': 1, 'model__penalty': 'l1', 'model...           0.708333  ...   \n",
       "42  {'model__C': 1, 'model__penalty': 'l1', 'model...           0.708333  ...   \n",
       "43  {'model__C': 1, 'model__penalty': 'l1', 'model...           0.933333  ...   \n",
       "44  {'model__C': 1, 'model__penalty': 'l2', 'model...           0.700000  ...   \n",
       "45  {'model__C': 1, 'model__penalty': 'l2', 'model...           0.766667  ...   \n",
       "46  {'model__C': 1, 'model__penalty': 'l2', 'model...           0.733333  ...   \n",
       "47  {'model__C': 1, 'model__penalty': 'l2', 'model...           0.991667  ...   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0            0.500000           0.500000           0.500000   \n",
       "1            0.500000           0.500000           0.500000   \n",
       "2            0.500000           0.500000           0.500000   \n",
       "3            0.500000           0.500000           0.500000   \n",
       "4            0.606897           0.641379           0.758621   \n",
       "5            0.537931           0.537931           0.627586   \n",
       "6            0.717241           0.786207           0.765517   \n",
       "7            0.772414           0.724138           0.793103   \n",
       "8            0.500000           0.500000           0.500000   \n",
       "9            0.500000           0.500000           0.500000   \n",
       "10           0.500000           0.500000           0.500000   \n",
       "11           0.500000           0.500000           0.500000   \n",
       "12           0.606897           0.648276           0.751724   \n",
       "13           0.565517           0.565517           0.696552   \n",
       "14           0.786207           0.800000           0.855172   \n",
       "15           0.800000           0.889655           0.827586   \n",
       "16           0.500000           0.500000           0.500000   \n",
       "17           0.500000           0.500000           0.500000   \n",
       "18           0.500000           0.500000           0.500000   \n",
       "19           0.710345           0.296552           0.344828   \n",
       "20           0.634483           0.689655           0.793103   \n",
       "21           0.772414           0.779310           0.786207   \n",
       "22           0.841379           0.806897           0.910345   \n",
       "23           0.841379           0.827586           0.848276   \n",
       "24           0.500000           0.500000           0.500000   \n",
       "25           0.648276           0.558621           0.648276   \n",
       "26           0.648276           0.551724           0.662069   \n",
       "27           0.744828           0.703448           0.682759   \n",
       "28           0.758621           0.779310           0.917241   \n",
       "29           0.862069           0.910345           0.882759   \n",
       "30           0.972414           0.786207           0.972414   \n",
       "31           0.993103           0.800000           0.841379   \n",
       "32           0.765517           0.848276           0.903448   \n",
       "33           0.896552           0.924138           0.868966   \n",
       "34           0.841379           0.868966           0.910345   \n",
       "35           0.889655           0.813793           0.737931   \n",
       "36           0.793103           0.875862           0.972414   \n",
       "37           0.951724           0.917241           0.917241   \n",
       "38           1.000000           0.986207           0.965517   \n",
       "39           1.000000           0.793103           0.786207   \n",
       "40           0.862069           0.958621           0.972414   \n",
       "41           1.000000           0.834483           0.931034   \n",
       "42           1.000000           1.000000           0.958621   \n",
       "43           1.000000           0.800000           0.937931   \n",
       "44           0.848276           0.958621           0.972414   \n",
       "45           0.993103           0.806897           0.896552   \n",
       "46           1.000000           1.000000           0.958621   \n",
       "47           1.000000           0.793103           0.751724   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0            0.500000           0.500000           0.500000   \n",
       "1            0.500000           0.500000           0.500000   \n",
       "2            0.500000           0.500000           0.500000   \n",
       "3            0.500000           0.500000           0.500000   \n",
       "4            0.751724           0.620690           0.853448   \n",
       "5            0.620690           0.525862           0.715517   \n",
       "6            0.675862           0.741379           0.879310   \n",
       "7            0.565517           0.767241           0.913793   \n",
       "8            0.500000           0.500000           0.500000   \n",
       "9            0.500000           0.500000           0.500000   \n",
       "10           0.500000           0.500000           0.500000   \n",
       "11           0.500000           0.500000           0.500000   \n",
       "12           0.751724           0.629310           0.853448   \n",
       "13           0.627586           0.534483           0.715517   \n",
       "14           0.703448           0.844828           0.905172   \n",
       "15           0.613793           0.818966           0.913793   \n",
       "16           0.500000           0.500000           0.500000   \n",
       "17           0.500000           0.500000           0.500000   \n",
       "18           0.500000           0.500000           0.500000   \n",
       "19           0.351724           0.431034           0.137931   \n",
       "20           0.765517           0.698276           0.862069   \n",
       "21           0.648276           0.741379           0.913793   \n",
       "22           0.793103           0.939655           0.931034   \n",
       "23           0.779310           0.956897           0.982759   \n",
       "24           0.500000           0.500000           0.500000   \n",
       "25           0.772414           0.568966           0.612069   \n",
       "26           0.751724           0.568966           0.612069   \n",
       "27           0.655172           0.525862           0.784483   \n",
       "28           0.793103           0.887931           0.956897   \n",
       "29           0.793103           0.913793           0.974138   \n",
       "30           0.931034           1.000000           0.974138   \n",
       "31           0.958621           0.974138           1.000000   \n",
       "32           0.786207           0.939655           0.879310   \n",
       "33           0.882759           0.939655           0.922414   \n",
       "34           0.710345           1.000000           0.956897   \n",
       "35           0.944828           0.948276           0.991379   \n",
       "36           0.827586           0.974138           1.000000   \n",
       "37           0.965517           0.982759           1.000000   \n",
       "38           0.979310           1.000000           0.974138   \n",
       "39           0.979310           0.956897           1.000000   \n",
       "40           0.910345           0.982759           0.991379   \n",
       "41           0.979310           0.982759           1.000000   \n",
       "42           0.972414           0.991379           0.974138   \n",
       "43           0.972414           0.922414           1.000000   \n",
       "44           0.896552           0.982759           1.000000   \n",
       "45           0.979310           0.982759           1.000000   \n",
       "46           0.986207           1.000000           0.974138   \n",
       "47           0.979310           0.922414           1.000000   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.500000         0.500000        0.000000               37  \n",
       "1            0.500000         0.500000        0.000000               37  \n",
       "2            0.500000         0.500000        0.000000               37  \n",
       "3            0.500000         0.500000        0.000000               37  \n",
       "4            0.706897         0.734138        0.105124               30  \n",
       "5            0.887931         0.584943        0.133747               35  \n",
       "6            0.939655         0.742126        0.139698               28  \n",
       "7            0.913793         0.745029        0.132903               27  \n",
       "8            0.500000         0.500000        0.000000               37  \n",
       "9            0.500000         0.500000        0.000000               37  \n",
       "10           0.500000         0.500000        0.000000               37  \n",
       "11           0.500000         0.489339        0.047524               47  \n",
       "12           0.715517         0.735029        0.103740               29  \n",
       "13           0.887931         0.611092        0.127585               34  \n",
       "14           0.991379         0.793391        0.137029               23  \n",
       "15           0.913793         0.781782        0.131584               24  \n",
       "16           0.500000         0.500000        0.000000               37  \n",
       "17           0.500000         0.500000        0.000000               37  \n",
       "18           0.500000         0.501983        0.073935               36  \n",
       "19           0.439655         0.381379        0.154685               48  \n",
       "20           0.741379         0.761523        0.091605               25  \n",
       "21           0.939655         0.750747        0.128269               26  \n",
       "22           1.000000         0.833506        0.136350               22  \n",
       "23           0.974138         0.836006        0.127587               21  \n",
       "24           0.500000         0.500000        0.000000               37  \n",
       "25           0.715517         0.635201        0.080332               32  \n",
       "26           0.715517         0.627730        0.085681               33  \n",
       "27           0.922414         0.690948        0.116897               31  \n",
       "28           0.887931         0.844511        0.086332               19  \n",
       "29           0.982759         0.845057        0.124146               18  \n",
       "30           0.965517         0.882787        0.132650               14  \n",
       "31           1.000000         0.892500        0.116053               12  \n",
       "32           0.905172         0.858190        0.069613               16  \n",
       "33           0.982759         0.864655        0.111464               15  \n",
       "34           1.000000         0.838276        0.162176               20  \n",
       "35           0.965517         0.848132        0.135948               17  \n",
       "36           0.956897         0.884885        0.097513               13  \n",
       "37           1.000000         0.909914        0.105261                8  \n",
       "38           0.974138         0.927730        0.107274                3  \n",
       "39           1.000000         0.901580        0.105300               11  \n",
       "40           0.913793         0.906494        0.088491                9  \n",
       "41           1.000000         0.911839        0.108655                7  \n",
       "42           0.991379         0.929511        0.099046                1  \n",
       "43           1.000000         0.928305        0.079797                2  \n",
       "44           0.931034         0.904943        0.092090               10  \n",
       "45           1.000000         0.912845        0.097003                6  \n",
       "46           0.982759         0.925144        0.121317                4  \n",
       "47           0.991379         0.915086        0.103872                5  \n",
       "\n",
       "[48 rows x 22 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid_search.fit(x_train_vix, y_train_vix)\n",
    "df = pd.DataFrame(lr_grid_search.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f70597",
   "metadata": {},
   "source": [
    "2. Creating the Logistic Regression using the Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f96ad8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe_vix = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"polynomial\", PolynomialFeatures(1)),\n",
    "    (\"model\", LogisticRegression(class_weight = {0: 1, 1:2}, penalty = \"l1\", C = 1, solver = \"liblinear\", max_iter = 100))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f079d",
   "metadata": {},
   "source": [
    "3. Logistic Regression Results on Test-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5eb87e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ad83bc17d0>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob = log_pipe_vix.fit(x_train_vix, y_train_vix).predict_proba(x_test_vix)\n",
    "pred = log_pipe_vix.fit(x_train_vix, y_train_vix).predict(x_test_vix)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_vix, prob[:, 1], pos_label=1)\n",
    "auc1 = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label = \"Logistic Regression-with Vix: AUC = \" + str(auc1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "52ef0def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ad83bc3210>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_vix, pred)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eabded",
   "metadata": {},
   "source": [
    "## Logistic Regression for Data without VIX and Cycle Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5bbea8e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[268], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lr_grid_search\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(lr_grid_search\u001b[38;5;241m.\u001b[39mcv_results_)\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[0;32m    539\u001b[0m     X,\n\u001b[0;32m    540\u001b[0m     y,\n\u001b[0;32m    541\u001b[0m     raw_predictions,\n\u001b[0;32m    542\u001b[0m     sample_weight,\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[0;32m    544\u001b[0m     X_val,\n\u001b[0;32m    545\u001b[0m     y_val,\n\u001b[0;32m    546\u001b[0m     sample_weight_val,\n\u001b[0;32m    547\u001b[0m     begin_at_stage,\n\u001b[0;32m    548\u001b[0m     monitor,\n\u001b[0;32m    549\u001b[0m )\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[0;32m    616\u001b[0m     i,\n\u001b[0;32m    617\u001b[0m     X,\n\u001b[0;32m    618\u001b[0m     y,\n\u001b[0;32m    619\u001b[0m     raw_predictions,\n\u001b[0;32m    620\u001b[0m     sample_weight,\n\u001b[0;32m    621\u001b[0m     sample_mask,\n\u001b[0;32m    622\u001b[0m     random_state,\n\u001b[0;32m    623\u001b[0m     X_csc,\n\u001b[0;32m    624\u001b[0m     X_csr,\n\u001b[0;32m    625\u001b[0m )\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    254\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    256\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 257\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(X, residual, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    260\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    261\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_grid_search.fit(x_train, y_train)\n",
    "df = pd.DataFrame(lr_grid_search.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5c0bbaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"polynomial\", PolynomialFeatures(1)),\n",
    "    (\"model\", LogisticRegression(class_weight = {0: 1, 1:2}, penalty = \"l1\", C = 1, solver = \"liblinear\", max_iter = 100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ef3b6bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ad84d317d0>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7yElEQVR4nO3deXhU5d3/8c9kmWySsIewGBbZKSBJQbCICwaBCm4FK7IJVoqIgLYF4RJBLT8VEbAsLixqQSmb0qcIxEogCC7ERNFQUfYlSEElLIEsfH9/8DAPQyYhE0IOCe/Xdc11mXPuc+Y794zMZ+5zn3NcZmYCAABwSIDTBQAAgKsbYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFGEEQAA4KggpwsoijNnzujAgQOqUKGCXC6X0+UAAIAiMDMdO3ZMNWvWVEBAweMfZSKMHDhwQHXq1HG6DAAAUAx79+5V7dq1C1xfJsJIhQoVJJ19MZGRkQ5XAwAAiiIzM1N16tTxfI8XpEyEkXOHZiIjIwkjAACUMRebYsEEVgAA4CjCCAAAcBRhBAAAOIowAgAAHEUYAQAAjiKMAAAARxFGAACAowgjAADAUYQRAADgKL/DyPr163XnnXeqZs2acrlcev/99y+6zbp16xQXF6fQ0FDVr19fs2fPLk6tAACgHPI7jJw4cUKtWrXS3/72tyK137lzp7p166aOHTsqNTVVTz31lIYPH66lS5f6XSwAACh//L43TdeuXdW1a9cit589e7auvfZaTZ06VZLUtGlTbd68WZMnT9a9997r79MDVx0zU1ZOntNlACjnwoIDL3oPmcvlst8ob9OmTUpISPBa1qVLF82ZM0c5OTkKDg7Ot83p06d1+vRpz9+ZmZmXu0zgimRmum/2JqXs/tnpUgCUc+kTuyjc7cz9cy/7BNaDBw8qOjraa1l0dLRyc3N1+PBhn9tMmjRJUVFRnkedOnUud5nAFSkrJ48gAqDcK5UIdOGwj5n5XH7OmDFjNGrUKM/fmZmZBBJc9TaP66xwd6DTZQAop8KCnfv35bKHkRo1aujgwYNeyw4dOqSgoCBVqVLF5zYhISEKCQm53KUBZUq4O9CxIVQAuJwu+2Ga9u3bKzEx0WvZmjVrFB8f73O+CAAAuLr4HUaOHz+utLQ0paWlSTp76m5aWpr27Nkj6ewhln79+nnaDxkyRLt379aoUaO0detWzZ07V3PmzNGTTz5ZMq8AAACUaX6P+W7evFm33HKL5+9zczv69++v+fPnKyMjwxNMJKlevXpauXKlRo4cqRkzZqhmzZqaPn06p/UCAABJxQgjN998s2cCqi/z58/Pt6xTp0768ssv/X0qAABwFeDeNAAAwFGEEQAA4CjCCAAAcBRhBAAAOIowAgAAHEUYAQAAjuLa0iiXzExZOXlOl3HJTmaX/dcAABdDGEG5Y2a6b/Ym7nYLAGUEh2lQ7mTl5JW7IBIfW8nRO2oCwOXEyAjKtc3jOivcXfa/xMOCA+VyuZwuAwAuC8IIyrVwd6DC3XzMAeBKxmEaAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAU18mG38xMWTlX7q3tT2ZfubUBAPIjjMAvZqb7Zm8qd3fFBQA4h8M08EtWTl6ZCSLxsZUUFlz279gLAOUdIyMots3jOivcfeV+2YcFB8rlcjldBgDgIggjKLZwd6DC3XyEAACXhsM0AADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRXD7zKlXcO+9yR1wAQEkjjFyFuPMuAOBKwmGaq1BJ3HmXO+ICAEoKIyNXueLeeZc74gIASgph5CrHnXcBAE7jMA0AAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFGEEQAA4CjCCAAAcBRhBAAAOIrrgF9FzExZOXk6mZ3ndCkAAHgQRq4SZqb7Zm+65Lv1AgBQ0jhMc5XIysnLF0TiYyspLNj/O/YCAFCSGBm5Cm0e11nh7kCFBQfK5XI5XQ4A4CpHGLkKhbsDFe7mrQcAXBk4TAMAABxFGAEAAI4qVhiZOXOm6tWrp9DQUMXFxSk5ObnQ9gsWLFCrVq0UHh6umJgYDRw4UEeOHClWwQAAoHzxO4wsWrRII0aM0NixY5WamqqOHTuqa9eu2rNnj8/2GzZsUL9+/TRo0CB9++23Wrx4sb744gsNHjz4kosHAABln99hZMqUKRo0aJAGDx6spk2baurUqapTp45mzZrls/2nn36qunXravjw4apXr55+85vf6JFHHtHmzZsvuXgAAFD2+RVGsrOzlZKSooSEBK/lCQkJ2rhxo89tOnTooH379mnlypUyM/34449asmSJunfvXuDznD59WpmZmV4PAABQPvkVRg4fPqy8vDxFR0d7LY+OjtbBgwd9btOhQwctWLBAvXv3ltvtVo0aNVSxYkW9+uqrBT7PpEmTFBUV5XnUqVPHnzIBAEAZUqwJrBdeKMvMCrx4Vnp6uoYPH66nn35aKSkpWrVqlXbu3KkhQ4YUuP8xY8bo6NGjnsfevXuLUyYAACgD/LryVdWqVRUYGJhvFOTQoUP5RkvOmTRpkm688Ub96U9/kiS1bNlSERER6tixo5577jnFxMTk2yYkJEQhISH+lAYAAMoov0ZG3G634uLilJiY6LU8MTFRHTp08LnNyZMnFRDg/TSBgWfvh2Jm/jw9AAAoh/y+JvioUaPUt29fxcfHq3379nr99de1Z88ez2GXMWPGaP/+/Xr77bclSXfeeacefvhhzZo1S126dFFGRoZGjBihtm3bqmbNmiX7aq5yZqasnDyf605m+14OAIDT/A4jvXv31pEjRzRx4kRlZGSoRYsWWrlypWJjYyVJGRkZXtccGTBggI4dO6a//e1veuKJJ1SxYkXdeuuteuGFF0ruVUBmpvtmb8p3Z14AAK50LisDx0oyMzMVFRWlo0ePKjIy0ulyrkgns3PV7OnVF20XH1tJi4e05269AIDLrqjf39y6tRzaPK6zwt2BPteFBQcSRAAAVxTCSDkU7g5UuJu3FgBQNnDXXgAA4CjCCAAAcBRhBAAAOIowAgAAHEUYAQAAjiKMAAAARxFGAACAowgjAADAUYQRAADgKC7TeQUo7G67RcVdeQEAZRVhxGHcbRcAcLXjMI3DsnLySjSIxMdWUliw75vkAQBwJWJk5ApS2N12i4q78gIAyhrCyBWEu+0CAK5GHKYBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFGEEQAA4CjCCAAAcBRhBAAAOIowAgAAHEUYAQAAjiKMAAAARxFGAACAowgjAADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFGEEQAA4CjCCAAAcBRhBAAAOCrI6QKuBmamrJw8n+tOZvteDgDA1aJYYWTmzJl66aWXlJGRoebNm2vq1Knq2LFjge1Pnz6tiRMn6u9//7sOHjyo2rVra+zYsXrooYeKXXhZYWa6b/Ympez+2elSAAC4IvkdRhYtWqQRI0Zo5syZuvHGG/Xaa6+pa9euSk9P17XXXutzm169eunHH3/UnDlzdN111+nQoUPKzc295OLLgqycvCIFkfjYSgoLDiyFigAAuLK4zMz82aBdu3Zq06aNZs2a5VnWtGlT3XXXXZo0aVK+9qtWrdL999+vHTt2qHLlysUqMjMzU1FRUTp69KgiIyOLtQ+nnMzOVbOnV0uSNo/rrHC378ARFhwol8tVmqUBAHBZFfX7268JrNnZ2UpJSVFCQoLX8oSEBG3cuNHnNitWrFB8fLxefPFF1apVS40aNdKTTz6prKysAp/n9OnTyszM9HqUB+HuQIW7g3w+CCIAgKuVX4dpDh8+rLy8PEVHR3stj46O1sGDB31us2PHDm3YsEGhoaFavny5Dh8+rKFDh+qnn37S3LlzfW4zadIkTZgwwZ/SAABAGVWsU3sv/BVvZgX+sj9z5oxcLpcWLFigtm3bqlu3bpoyZYrmz59f4OjImDFjdPToUc9j7969xSkTAACUAX6NjFStWlWBgYH5RkEOHTqUb7TknJiYGNWqVUtRUVGeZU2bNpWZad++fWrYsGG+bUJCQhQSEuJPaQAAoIzya2TE7XYrLi5OiYmJXssTExPVoUMHn9vceOONOnDggI4fP+5Ztm3bNgUEBKh27drFKBkAAJQnfh+mGTVqlN58803NnTtXW7du1ciRI7Vnzx4NGTJE0tlDLP369fO0f+CBB1SlShUNHDhQ6enpWr9+vf70pz/poYceUlhYWMm9EgAAUCb5fZ2R3r1768iRI5o4caIyMjLUokULrVy5UrGxsZKkjIwM7dmzx9P+mmuuUWJioh577DHFx8erSpUq6tWrl5577rmSexUAAKDM8vs6I04oL9cZSZ/YReFursAPALg6XJbrjAAAAJQ0wggAAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFGEEQAA4CjCCAAAcBRhBAAAOIowAgAAHEUYAQAAjiKMAAAARxFGAACAowgjAADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFFBThdwJTMzZeXkXdI+TmZf2vYAAJR3hJECmJnum71JKbt/droUAADKNQ7TFCArJ69Eg0h8bCWFBQeW2P4AACgvGBkpgs3jOivcfWlBIiw4UC6Xq4QqAgCg/CCMFEG4O1DhbroKAIDLgcM0AADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFGEEQAA4CjCCAAAcFSxwsjMmTNVr149hYaGKi4uTsnJyUXa7pNPPlFQUJBat25dnKcFAADlkN9hZNGiRRoxYoTGjh2r1NRUdezYUV27dtWePXsK3e7o0aPq16+fbrvttmIXCwAAyh+/w8iUKVM0aNAgDR48WE2bNtXUqVNVp04dzZo1q9DtHnnkET3wwANq3759sYsFAADlj19hJDs7WykpKUpISPBanpCQoI0bNxa43bx587R9+3aNHz++SM9z+vRpZWZmej0AAED55FcYOXz4sPLy8hQdHe21PDo6WgcPHvS5zffff6/Ro0drwYIFCgoKKtLzTJo0SVFRUZ5HnTp1/CkTAACUIcWawOpyubz+NrN8yyQpLy9PDzzwgCZMmKBGjRoVef9jxozR0aNHPY+9e/cWp0wAAFAGFG2o4n9VrVpVgYGB+UZBDh06lG+0RJKOHTumzZs3KzU1VcOGDZMknTlzRmamoKAgrVmzRrfeemu+7UJCQhQSEuJPaQAAoIzya2TE7XYrLi5OiYmJXssTExPVoUOHfO0jIyO1ZcsWpaWleR5DhgxR48aNlZaWpnbt2l1a9QAAoMzza2REkkaNGqW+ffsqPj5e7du31+uvv649e/ZoyJAhks4eYtm/f7/efvttBQQEqEWLFl7bV69eXaGhofmWAwCAq5PfYaR37946cuSIJk6cqIyMDLVo0UIrV65UbGysJCkjI+Oi1xwBAAA4x2Vm5nQRF5OZmamoqCgdPXpUkZGRpfKcJ7Nz1ezp1ZKk9IldFO72O7cBAHBVK+r3N/emAQAAjiKMAAAARxFGAACAowgjAADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACO4rKi5zEzZeXkSZJOZuc5XA0AAFcHwsj/MjPdN3uTUnb/7HQpAABcVThM87+ycvJ8BpH42EoKCw50oCIAAK4OjIz4sHlcZ4W7zwaQsOBAuVwuhysCAKD8Ioz4EO4O5C69AACUEg7TAAAARxFGAACAowgjAADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFGEEQAA4CjCCAAAcBRhBAAAOIowAgAAHEUYAQAAjiKMAAAARxFGAACAowgjAADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKOKFUZmzpypevXqKTQ0VHFxcUpOTi6w7bJly3T77berWrVqioyMVPv27bV69epiFwwAAMoXv8PIokWLNGLECI0dO1apqanq2LGjunbtqj179vhsv379et1+++1auXKlUlJSdMstt+jOO+9UamrqJRcPAADKPpeZmT8btGvXTm3atNGsWbM8y5o2baq77rpLkyZNKtI+mjdvrt69e+vpp58uUvvMzExFRUXp6NGjioyM9KfcIjuZnatmT58dsUmf2EXh7qDL8jwAAFwtivr97dfISHZ2tlJSUpSQkOC1PCEhQRs3bizSPs6cOaNjx46pcuXKBbY5ffq0MjMzvR4AAKB88iuMHD58WHl5eYqOjvZaHh0drYMHDxZpHy+//LJOnDihXr16Fdhm0qRJioqK8jzq1KnjT5kAAKAMKdYEVpfL5fW3meVb5su7776rZ555RosWLVL16tULbDdmzBgdPXrU89i7d29xygQAAGWAXxMjqlatqsDAwHyjIIcOHco3WnKhRYsWadCgQVq8eLE6d+5caNuQkBCFhIT4UxoAACij/BoZcbvdiouLU2JiotfyxMREdejQocDt3n33XQ0YMEALFy5U9+7di1cpAAAol/w+ZWTUqFHq27ev4uPj1b59e73++uvas2ePhgwZIunsIZb9+/fr7bfflnQ2iPTr10/Tpk3TDTfc4BlVCQsLU1RUVAm+FAAAUBb5HUZ69+6tI0eOaOLEicrIyFCLFi20cuVKxcbGSpIyMjK8rjny2muvKTc3V48++qgeffRRz/L+/ftr/vz5l/4KAABAmeb3dUacwHVGAAAoe4r6/X1Vf+OambJy8iRJJ7PzHK4GAICr01UbRsxM983epJTdPztdCgAAV7Wr9q69WTl5PoNIfGwlhQUHOlARAABXp6t2ZOR8m8d1Vrj7bAAJCw4s0gXcAABAySCMSAp3BzJhFQAAh1y1h2kAAMCVgTACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFGEEQAA4CjCCAAAcBRhBAAAOIowAgAAHEUYAQAAjiKMAAAARxFGAACAowgjAADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICjCCMAAMBRhBEAAOAowggAAHAUYQQAADiKMAIAABxFGAEAAI4ijAAAAEcRRgAAgKMIIwAAwFGEEQAA4KggpwsoS/Ly8pSTk+N0GQAAXBGCg4MVGBh4yfshjBSBmengwYP65ZdfnC4FAIArSsWKFVWjRg25XK5i74MwUgTngkj16tUVHh5+SR0OAEB5YGY6efKkDh06JEmKiYkp9r4IIxeRl5fnCSJVqlRxuhwAAK4YYWFhkqRDhw6pevXqxT5kwwTWizg3RyQ8PNzhSgAAuPKc+368lDmVhJEi4tAMAAD5lcT3I2EEAAA4ijCCS1K3bl1NnTq12NvPnz9fFStWLLF6ypObb75ZI0aMcLoML0V9v1wul95///0Sf/4BAwborrvuKvH9AnAWYaQcK41/uL/44gv94Q9/KFJbX8Gld+/e2rZtW7Gff/78+XK5XJ5HdHS07rzzTn377bfF3ueVYtmyZXr22WedLsPLhe/XM888o9atW1/yfn/1q19p8ODBPte9++67Cg4O1o8//qhp06Zp/vz5l/x8vmRlZalSpUqqXLmysrKy8q0vKGCNGDFCN998s9eygwcP6rHHHlP9+vUVEhKiOnXq6M4779S///3vy1L7OevWrVNcXJxCQ0NVv359zZ49+6Lb/Pvf/1aHDh1UoUIFxcTE6C9/+Ytyc3M965OSktSzZ0/FxMQoIiJCrVu31oIFC7z2MWDAAK//D889mjdv7mnzxhtvqGPHjqpUqZIqVaqkzp076/PPP/faz7FjxzRixAjFxsYqLCxMHTp00BdffOHV5vjx4xo2bJhq166tsLAwNW3aVLNmzcr3ujZt2qRbb71VERERqlixom6++Waf7+vp06fVunVruVwupaWlea3z9ZrO79NnnnnGZ5uIiAiv/vPV5j//+Y+nTU5OjiZOnKgGDRooNDRUrVq10qpVq/LVOnPmTNWrV0+hoaGKi4tTcnKyX32za9cun7W4XC4tXry40HpdLle+96IkEUZwSapVq3ZJk3vDwsJUvXr1S6ohMjJSGRkZOnDggP71r3/pxIkT6t69u7Kzsy9pvxdzuS+AV7lyZVWoUOGyPoe/SuL98mXQoEH6xz/+oZMnT+ZbN3fuXP32t79VdHS0oqKiLttI2tKlS9WiRQs1a9ZMy5YtK/Z+du3apbi4OH388cd68cUXtWXLFq1atUq33HKLHn300RKs2NvOnTvVrVs3dezYUampqXrqqac0fPhwLV26tMBtvv76a3Xr1k133HGHUlNT9d5772nFihUaPXq0p83GjRvVsmVLLV26VF9//bUeeugh9evXT//85z89baZNm6aMjAzPY+/evapcubJ+97vfedokJSXp97//vdauXatNmzbp2muvVUJCgvbv3+9pM3jwYCUmJuqdd97Rli1blJCQoM6dO3u1GTlypFatWqW///3v2rp1q0aOHKnHHntMH3zwgafNpk2bdMcddyghIUGff/65vvjiCw0bNkwBAfm/8v785z+rZs2aBfbRvHnzvF5b//79PeuefPJJr3UZGRlq1qyZ1+s+57vvvvNq17BhQ8+6cePG6bXXXtOrr76q9PR0DRkyRHfffbdSU1M9bRYtWqQRI0Zo7NixSk1NVceOHdW1a1ft2bOnyH1Tp06dfPVOmDBBERER6tq1qySpQ4cO+doMHjxYdevWVXx8fIH9dMmsDDh69KhJsqNHj5bYPk+czrHYv/yPxf7lf+zE6ZwC22VlZVl6erplZWWV2HOXlv79+1vPnj0LXJ+UlGS//vWvze12W40aNewvf/mL5eT8X19kZmbaAw88YOHh4VajRg2bMmWKderUyR5//HFPm9jYWHvllVc8f48fP97q1KljbrfbYmJi7LHHHjMzs06dOpkkr4eZ2bx58ywqKsqrrg8++MDi4uIsJCTEqlSpYnfffXeBr8HX9itWrDBJ9vXXX3uWffLJJ9axY0cLDQ212rVr22OPPWbHjx/3rD9w4IB169bNQkNDrW7durZgwYJ8r02SzZo1y3r06GHh4eH29NNPe56vTZs2FhISYvXq1bNnnnnGqx8L6hMzsxkzZth1111nISEhVr16dbv33ns96y7s659++sn69u1rFStWtLCwMLvjjjts27Zt+fpi1apV1qRJE4uIiLAuXbrYgQMHCuy/FStWWFRUlOXl5ZmZWWpqqkmyJ5980tPmD3/4g91///35+nvevHn53tN58+Z5+uqNN96wu+66y8LCwuy6666zDz74oMA6Dh8+bG632+bPn++1fPfu3RYQEGD//Oc/zcz7M33o0CGLjo62559/3tP+008/teDgYFu9enWBz1WQm2++2WbPnm2zZs2yW265Jd96SbZ8+fJ8yx9//HHr1KmT5++uXbtarVq1vD5f5/z8889+11VUf/7zn61JkyZeyx555BG74YYbCtxmzJgxFh8f77Vs+fLlFhoaapmZmQVu161bNxs4cGCB65cvX24ul8t27dpVYJvc3FyrUKGCvfXWW2ZmdvLkSQsMDLT/+Z//8WrXqlUrGzt2rOfv5s2b28SJE73atGnTxsaNG+f5u127dl5/F2TlypXWpEkT+/bbb02Spaameq0v6D0vSFpamkmy9evXe5atXbvWJBX63sfExNjf/vY3r2U9e/a0Pn36eP5u27atDRkyxKtNkyZNbPTo0Z6/i9I3F2rdurU99NBDBa7Pzs626tWr59vv+Qr7nizq9zcjI8VgZjqZnevIw8xK5DXs379f3bp1069//Wt99dVXmjVrlubMmaPnnnvO02bUqFH65JNPtGLFCiUmJio5OVlffvllgftcsmSJXnnlFb322mv6/vvv9f777+tXv/qVpLOHHGrXrq2JEyd60rYv//rXv3TPPfeoe/fuSk1N1b///W+/0vgvv/yihQsXSjp7mWJJ2rJli7p06aJ77rlHX3/9tRYtWqQNGzZo2LBhnu369eunAwcOKCkpSUuXLtXrr7/uuZDP+caPH6+ePXtqy5Yteuihh7R69Wo9+OCDGj58uNLT0/Xaa69p/vz5ev755y/aJ5s3b9bw4cM1ceJEfffdd1q1apVuuummAl/bgAEDtHnzZq1YsUKbNm2Smalbt25eIzQnT57U5MmT9c4772j9+vXas2ePnnzyyQL3edNNN+nYsWOeX2Dr1q1T1apVtW7dOk+bpKQkderUKd+2vXv31hNPPKHmzZt73tPevXt71k+YMEG9evXy/Pru06ePfvrpJ591VKlSRT179tS8efO8ls+bN0/R0dGeX23nq1atmubOnatnnnlGmzdv1vHjx/Xggw9q6NChSkhIkPR/w9JJSUkF9oEkbd++XZs2bVKvXr3Uq1cvbdy4UTt27Ch0G19++uknrVq1So8++qjXUP05hY3qLFiwQNdcc02hjwsPj5xv06ZNntd9TpcuXbR58+YCR/FOnz6t0NBQr2VhYWE6deqUUlJSCnyuo0ePqnLlygWunzNnjjp37qzY2NgC25w8eVI5OTme/eTm5iovL89nPRs2bPD8/Zvf/EYrVqzQ/v37ZWZau3attm3bpi5dukg6e72Lzz77TNWrV1eHDh0UHR2tTp06ee1Dkn788Uc9/PDDeueddwod3R02bJiqVq2qX//615o9e7bOnDlTYNs333xTjRo1UseOHfOtu/766xUTE6PbbrtNa9eu9VpX0Ptwrubs7GylpKTke38TEhK0cePGIvfNhVJSUpSWlqZBgwYV+JpWrFihw4cPa8CAAQW2KRGFRpUCzJgxw+rWrWshISHWpk0brxToS1JSktcvx1mzZvn1fFfayMj525b2o7BaL1TYyMhTTz1ljRs3tjNnzniWzZgxw6655hrLy8uzzMxMCw4OtsWLF3vW//LLLxYeHl7gyMjLL79sjRo1suzsbJ/PeeFIg1n+kY327dt7/Rq4mHO/ziMiIiw8PNzzC71Hjx6eNn379rU//OEPXtslJydbQECAZWVl2datW02SffHFF57133//vUnKNzIyYsQIr/107NjR/vrXv3ote+eddywmJsbMCu+TpUuXWmRkZIG/QM8fGdm2bZtJsk8++cSz/vDhwxYWFmb/+Mc/vPrihx9+8LSZMWOGRUdH+9z/OW3atLHJkyebmdldd91lzz//vLndbsvMzLSMjAyTZFu3bvU8x/nv1/jx461Vq1b59inJ69fY8ePHzeVy2YcfflhgHR9++KG5XC7bvn27mZmdOXPG6tata2PGjPG08fWZHjp0qDVq1Mj69OljLVq08Pp/dd++fda4cWP77LPPCu2Dp556yu666y7P3z179vT6NX7uNV1sZOSzzz4zSbZs2bJCn8+XzMxM+/777wt9FDZa0bBhQ69RIrOzI4KSChwdW716tQUEBNjChQstNzfX9u3bZ7/5zW9Mki1cuNDnNosXLza3223ffPONz/UHDhywwMBAW7RoUaGvd+jQodagQQOv96t9+/bWqVMn279/v+Xm5to777xjLpfLGjVq5Glz+vRp69evn0myoKAgc7vd9vbbb3vWb9q0ySRZ5cqVbe7cufbll1/aiBEjzO12e0YSz5w5Y3fccYc9++yzZma2c+dOnyMjzz77rG3cuNFSU1Nt8uTJFh4e7tnmQqdOnbJKlSrZCy+84LX8P//5j73++uuWkpJiGzdutD/+8Y/mcrls3bp1nja///3vrVmzZrZt2zbLy8uzNWvWWFhYmLndbjMz279/f77//83Mnn/+eb/65kJ//OMfrWnTpgWuNzs70te1a9dC2zgyMlKU41bnK85xTFx+W7duVfv27b3OD7/xxht1/Phx7du3Tzt27FBOTo7atm3rWR8VFaXGjRsXuM/f/e53ysrKUv369fXwww9r+fLlXhPhiiItLU233XabX9tUqFBBaWlpSklJ0ezZs9WgQQOvSWYpKSmaP3++1y/MLl266MyZM9q5c6e+++47BQUFqU2bNp5trrvuOlWqVCnfc104SpOSkqKJEyd67fvhhx9WRkaGTp48WWif3H777YqNjVX9+vXVt29fLViwwOecCens+xUUFKR27dp5llWpUkWNGzfW1q1bPcvCw8PVoEEDz98xMTGeEZ7k5GSfv7JvvvlmJSUlycyUnJysnj17qkWLFtqwYYPWrl2r6OhoNWnSpMjvxzktW7b0/HdERIQqVKjgc7TpnISEBNWuXdszOvLxxx9r165dGjhwYKHPM3nyZOXm5uof//iHFixY4PULs1atWvrPf/7j9Tm+UF5ent566y09+OCDnmUPPvig3nrrLeXl5V30dZ7P/nfksjjXXahQoYKuu+66Qh8Xm0N04fNerJ6EhAS99NJLGjJkiEJCQtSoUSN1795dknxeSTMpKUkDBgzQG2+84TU59XznzrgqbPL8iy++qHfffVfLli3zer/eeecdmZlq1aqlkJAQTZ8+XQ888IBXLdOnT9enn36qFStWKCUlRS+//LKGDh2qjz76SJI8IxePPPKIBg4cqOuvv16vvPKKGjdurLlz50qSXn31VWVmZmrMmDEF1iidncvRvn17tW7dWk888YQmTpyol156yWfbZcuW6dixY+rXr5/X8saNG+vhhx9WmzZt1L59e82cOVPdu3fX5MmTPW2mTZumhg0bqkmTJnK73Ro2bJgGDhyY7z3w9f6ev+xifXO+rKwsLVy4sNBRkX379mn16tWFtikpfl8OfsqUKRo0aJBn5vvUqVO1evVqzZo1S5MmTcrXfvbs2br22ms9Z1E0bdpUmzdv1uTJk3XvvfdeWvUOCQsOVPpE38NepfHcJeHCD/G5ZdLZD3xB/4hZIYeJ6tSpo++++06JiYn66KOPNHToUL300ktat26d55DJxZy7tLA/AgICdN1110mSmjRpooMHD6p3795av369pLP/OD3yyCMaPnx4vm2vvfZafffddz736+u1Xjj0fubMGU2YMEH33HNPvrahoaGF9kmFChX05ZdfKikpSWvWrNHTTz+tZ555Rl988UW+4fyC+v3C9/HCfj7/vYyPj/c6WyA6OlrS2TAyZ84cffXVVwoICFCzZs3UqVMnrVu3Tj///LPPQzRF4auWwoa4AwICNGDAAM2fP18TJkzQvHnzdNNNN3lN9PNlx44dOnDggM6cOaPdu3d7haCiWL16tfbv3+91iEk6G1LWrFnjOURUoUIFHT16NN/2v/zyi6KioiRJDRs2lMvl0tatW/0+k23BggV65JFHCm3z2muvqU+fPj7X1ahRQwcPHvRadujQIQUFBRV6K4tRo0Zp5MiRysjIUKVKlbRr1y6NGTNG9erV82q3bt063XnnnZoyZUq+L9xzzExz585V37595Xa7fbaZPHmy/vrXv+qjjz7K9141aNBA69at04kTJ5SZmamYmBj17t3bU0tWVpaeeuopLV++3BOaWrZsqbS0NE2ePFmdO3f23B+lWbNmXvtu2rSp50fzxx9/rE8//VQhISFebeLj49WnTx+99dZbPmu/4YYblJmZqR9//NHz/885b775pn7729+qRo0aPre9cD9///vfPX9Xq1ZN77//vk6dOqUjR46oZs2aGj16tOd1V61aVYGBgT7f33N1FKVvzrdkyRKdPHmywPdSOnuYtEqVKurRo8dFX9Ol8mtkpKjHrc5X3OOYmZmZXo8ricvlUrg7yJFHSV0JtlmzZtq4caPXl9zGjRtVoUIF1apVSw0aNFBwcLDXqXeZmZn6/vvvC91vWFiYevTooenTpyspKUmbNm3Sli1bJElut/uivzRbtmx5yac/jhw5Ul999ZWWL18uSWrTpo2+/fZbn7803W63mjRpotzcXK+Z6z/88EOR7tLcpk0bfffddz73fW7mfmF9EhQUpM6dO+vFF1/U119/rV27dunjjz/O9zzNmjVTbm6uPvvsM8+yI0eOaNu2bWratGmR+iUsLMznr+xz80amTp2qTp06yeVyqVOnTkpKSipwvsg5RXlP/TFw4EDt27dPy5Yt07Jlyy76iyw7O1t9+vRR79699dxzz2nQoEH68ccf/XrOOXPm6P7771daWprXo0+fPpozZ46nXZMmTfKd2mhmSklJ8YwYVq5cWV26dNGMGTN04sSJfM9V2GeqR48e+Wq48FHYl0L79u2VmJjotWzNmjWKj4+/6I8Bl8ulmjVrKiwsTO+++67q1KnjNVKYlJSk7t276//9v/9X6Kn869at0w8//FDg+/bSSy/p2Wef1apVqwqdCxYREaGYmBj9/PPPWr16tXr27Cnp7BlsOTk5+c6KCQwM9ATdunXrqmbNmvl+ZGzbts0zh2X69On66quvPP26cuVKSWdH/s/N9/IlNTVVoaGh+X4s7Ny5U2vXri3yCEJqaqrPm8qFhoaqVq1ays3N1dKlSz2v2+12Ky4uLt/7m5iYqA4dOkgqWt+cb86cOerRo4eqVavms0Yz07x589SvX78i/5i8JIUexLlAUY9bna84xzHHjx+fb5a+rqA5I2VF//797eabb7bU1FSvx+7du23fvn0WHh5ujz76qG3dutXef/99q1q1qo0fP96z/eDBg61evXr28ccf2zfffGP33nuvVahQwWvexPnzQObNm2dvvvmmbdmyxbZv325jx461sLAwO3z4sJmZ3X777dajRw/bt2+f/fe///Vsc/4chLVr11pAQIA9/fTTlp6ebl9//XW+Y7Dn83U2jZnZqFGj7Fe/+pWdOXPGvvrqKwsLC7OhQ4daamqqbdu2zT744AMbNmyYp33nzp2tTZs29tlnn9mXX35pt9xyi4WFhdnUqVM9beRjzsCqVassKCjIxo8fb998842lp6fbe++955lvUFif/POf/7Rp06ZZamqq7dq1y2bOnGkBAQGeY/EXnk3Ts2dPa9asmSUnJ1taWprdcccddt1113nmo/jqi+XLl1tR/jdv06aNBQYGemb0//TTTxYcHGyS7Ntvvy2wvxcsWGARERGWmppq//3vf+3UqVMF9lVUVJTnbJvC3HbbbVapUiWLjIy0EydOeK27cM7Ik08+aXXr1rWjR49aXl6e3XTTTda9e3fP+ovNGTl06JAFBwf7nMuyZs0aCw4OtkOHDpmZ2aJFiyw0NNReffVV++677ywtLc2GDh1qYWFhXmeN7Nixw2rUqGHNmjWzJUuW2LZt2yw9Pd2mTZuW72yXkrRjxw4LDw+3kSNHWnp6us2ZM8eCg4NtyZIlnjbLli2zxo0be2334osv2tdff23ffPONTZw40YKDg73eu7Vr11p4eLiNGTPGMjIyPI8jR47kq+HBBx+0du3a+azvhRdeMLfbbUuWLPHaz7FjxzxtVq1aZR9++KHt2LHD1qxZY61atbK2bdt6zbnq1KmTNW/e3NauXWs7duywefPmWWhoqM2cOdPT5pVXXrHIyEhbvHixff/99zZu3DgLDQ31mk91Pl9zRlasWGGvv/66bdmyxX744Qd74403LDIy0oYPH55v+3HjxlnNmjUtNzc337pXXnnFli9fbtu2bbNvvvnGRo8ebZJs6dKlnjaffvqpLV261LZv327r16+3W2+91erVq+d1Bs57771nwcHBNmfOHEtPT7cRI0ZYRESE12evKH1jdnZO3MXmcH300UcmydLT0wtsc05JzBkpVhjZuHGj1/Lnnnsu3wf8nIYNG+ab4LdhwwaTZBkZGT63OXXqlB09etTz2Lt3b4mHkTNnztiJ0zl24nSO1yTOC5X1MOIr1PXv39/Mindqb9u2bb1OJTs/jCxfvtzatWtnkZGRFhERYTfccIN99NFHnrabNm2yli1bWkhISKGn9i5dutRat25tbrfbqlatavfcc0+Br7GgMLJ7924LCgryTKL7/PPP7fbbb7drrrnGIiIirGXLll4h+cCBA9a1a1cLCQmx2NhYW7hwoVWvXt1mz57taePrC9bs7D+gHTp0sLCwMIuMjLS2bdva66+/ftE+SU5Otk6dOlmlSpUsLCzMWrZs6TXpr6BTe6OioiwsLMy6dOni89Te8xU1jDzxxBMmyWtSYqtWraxatWpe/39c+BynTp2ye++91ypWrJjv1N7ihpGFCxeapHyTjs28w8jatWstKCjIkpOTPet3795tUVFRnn98z33JrF271udzTZ482SpWrOhzgnFOTo5VrlzZXn75Zc+y9957z+Lj4y0yMtKqV69uXbp0sc2bN+fb9sCBA/boo49abGysud1uq1WrlvXo0aPAOkpKUlKSXX/99eZ2u61u3br5ThY4N8n5fLfccotFRUVZaGiotWvXzlauXOm1vqB/R84/ndns7AT3sLAwz2f/QrGxsT73c/4PoEWLFln9+vU9/yY9+uij9ssvv3jtJyMjwwYMGGA1a9a00NBQa9y4sb388sv5/h2fNGmS1a5d28LDw619+/Zen5ML+QojH374obVu3dquueYaCw8PtxYtWtjUqVO9/o00M8vLy7PatWvbU0895XPfL7zwgjVo0MBCQ0OtUqVK9pvf/Mb+9a9/ebVJSkqypk2bei5n0LdvX9u/f3++fc2YMcPzmWrTpo3XJFh/+mbMmDFWu3Ztzyn9vvz+97+3Dh06FLj+fCURRlxmRT9XNDs7W+Hh4Vq8eLHuvvtuz/LHH39caWlpXqcDnnPTTTfp+uuv17Rp0zzLli9frl69eunkyZNFGv7JzMxUVFSUjh49qsjIyKKWWyJOnTqlnTt3eq56dzU7ceKEatWqpZdffrlUJjQ5ad++fapTp44++ugjvyfUAsDVpLDvyaJ+f/s1Z6Qox60udCnHMeGs1NRUvfvuu9q+fbu+/PJLz8S5c8cxy5OPP/5YK1as0M6dO7Vx40bdf//9qlu3bqHX/QAAlAy/T+0dNWqU3nzzTc2dO9dzudk9e/ZoyJAhkqQxY8Z4zc4dMmSIdu/erVGjRmnr1q2aO3eu5syZU+iFmHDlmDx5slq1aqXOnTvrxIkTSk5OVtWqVZ0uq8Tl5OToqaeeUvPmzXX33XerWrVqSkpKIjADQCnw+9Te3r1768iRI54rabZo0UIrV670zFLOyMjwuuZIvXr1tHLlSo0cOVIzZsxQzZo1NX369DJ7Wu/V5Prrry/0KozlSZcuXQq8SiEA4PLya86IU5gzAgDAlanU54wAAACUNMJIERV25UgAAK5WJfH96PeckauN2+1WQECADhw4oGrVqsntdpfYVVABACirzEzZ2dn673//q4CAgAJvAVAUhJGLCAgIUL169ZSRkaEDBw44XQ4AAFeU8PBwXXvttfkuRe8PwkgRuN1uXXvttcrNzS3R+3AAAFCWBQYGKijo0u+bRhgpIpfLpeDgYK47AQBACWMCKwAAcBRhBAAAOIowAgAAHFUm5oycu0hsZmamw5UAAICiOve9fbGLvZeJMHLs2DFJUp06dRyuBAAA+OvYsWOKiooqcH2ZuDfNmTNndODAAVWoUKFELziWmZmpOnXqaO/evaV+z5urDX1dOujn0kE/lw76uXRczn42Mx07dkw1a9Ys9DokZWJkJCAgQLVr175s+4+MjOSDXkro69JBP5cO+rl00M+l43L1c2EjIucwgRUAADiKMAIAABx1VYeRkJAQjR8/XiEhIU6XUu7R16WDfi4d9HPpoJ9Lx5XQz2ViAisAACi/ruqREQAA4DzCCAAAcBRhBAAAOIowAgAAHFXuw8jMmTNVr149hYaGKi4uTsnJyYW2X7duneLi4hQaGqr69etr9uzZpVRp2eZPPy9btky33367qlWrpsjISLVv316rV68uxWrLNn8/0+d88sknCgoKUuvWrS9vgeWEv/18+vRpjR07VrGxsQoJCVGDBg00d+7cUqq27PK3nxcsWKBWrVopPDxcMTExGjhwoI4cOVJK1ZZN69ev15133qmaNWvK5XLp/fffv+g2pf5daOXYe++9Z8HBwfbGG29Yenq6Pf744xYREWG7d+/22X7Hjh0WHh5ujz/+uKWnp9sbb7xhwcHBtmTJklKuvGzxt58ff/xxe+GFF+zzzz+3bdu22ZgxYyw4ONi+/PLLUq687PG3r8/55ZdfrH79+paQkGCtWrUqnWLLsOL0c48ePaxdu3aWmJhoO3futM8++8w++eSTUqy67PG3n5OTky0gIMCmTZtmO3bssOTkZGvevLndddddpVx52bJy5UobO3asLV261CTZ8uXLC23vxHdhuQ4jbdu2tSFDhngta9KkiY0ePdpn+z//+c/WpEkTr2WPPPKI3XDDDZetxvLA3372pVmzZjZhwoSSLq3cKW5f9+7d28aNG2fjx48njBSBv/384YcfWlRUlB05cqQ0yis3/O3nl156yerXr++1bPr06Va7du3LVmN5U5Qw4sR3Ybk9TJOdna2UlBQlJCR4LU9ISNDGjRt9brNp06Z87bt06aLNmzcrJyfnstValhWnny905swZHTt2TJUrV74cJZYbxe3refPmafv27Ro/fvzlLrFcKE4/r1ixQvHx8XrxxRdVq1YtNWrUSE8++aSysrJKo+QyqTj93KFDB+3bt08rV66UmenHH3/UkiVL1L1799Io+arhxHdhmbhRXnEcPnxYeXl5io6O9loeHR2tgwcP+tzm4MGDPtvn5ubq8OHDiomJuWz1llXF6ecLvfzyyzpx4oR69ep1OUosN4rT199//71Gjx6t5ORkBQWV2//dS1Rx+nnHjh3asGGDQkNDtXz5ch0+fFhDhw7VTz/9xLyRAhSnnzt06KAFCxaod+/eOnXqlHJzc9WjRw+9+uqrpVHyVcOJ78JyOzJyjsvl8vrbzPItu1h7X8vhzd9+Pufdd9/VM888o0WLFql69eqXq7xypah9nZeXpwceeEATJkxQo0aNSqu8csOfz/SZM2fkcrm0YMECtW3bVt26ddOUKVM0f/58Rkcuwp9+Tk9P1/Dhw/X0008rJSVFq1at0s6dOzVkyJDSKPWqUtrfheX2p1LVqlUVGBiYL2EfOnQoX+I7p0aNGj7bBwUFqUqVKpet1rKsOP18zqJFizRo0CAtXrxYnTt3vpxllgv+9vWxY8e0efNmpaamatiwYZLOfmmamYKCgrRmzRrdeuutpVJ7WVKcz3RMTIxq1arldav0pk2bysy0b98+NWzY8LLWXBYVp58nTZqkG2+8UX/6058kSS1btlRERIQ6duyo5557jtHrEuLEd2G5HRlxu92Ki4tTYmKi1/LExER16NDB5zbt27fP137NmjWKj49XcHDwZau1LCtOP0tnR0QGDBighQsXcry3iPzt68jISG3ZskVpaWmex5AhQ9S4cWOlpaWpXbt2pVV6mVKcz/SNN96oAwcO6Pjx455l27ZtU0BAgGrXrn1Z6y2ritPPJ0+eVECA99dWYGCgpP/75Y5L58h34WWbGnsFOHfa2Jw5cyw9Pd1GjBhhERERtmvXLjMzGz16tPXt29fT/tzpTCNHjrT09HSbM2cOp/YWgb/9vHDhQgsKCrIZM2ZYRkaG5/HLL7849RLKDH/7+kKcTVM0/vbzsWPHrHbt2nbffffZt99+a+vWrbOGDRva4MGDnXoJZYK//Txv3jwLCgqymTNn2vbt223Dhg0WHx9vbdu2deollAnHjh2z1NRUS01NNUk2ZcoUS01N9ZxCfSV8F5brMGJmNmPGDIuNjTW3221t2rSxdevWedb179/fOnXq5NU+KSnJrr/+enO73Va3bl2bNWtWKVdcNvnTz506dTJJ+R79+/cv/cLLIH8/0+cjjBSdv/28detW69y5s4WFhVnt2rVt1KhRdvLkyVKuuuzxt5+nT59uzZo1s7CwMIuJibE+ffrYvn37SrnqsmXt2rWF/pt7JXwXuswY2wIAAM4pt3NGAABA2UAYAQAAjiKMAAAARxFGAACAowgjAADAUYQRAADgKMIIAABwFGEEAAA4ijACAAAcRRgBAACOIowAAABHEUYAAICj/j+bxkpxyjgt8AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob = log_pipe.fit(x_train, y_train).predict_proba(x_test)\n",
    "pred = log_pipe.fit(x_train, y_train).predict(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob[:, 1], pos_label=1)\n",
    "auc1 = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label = \"Logistic Regression-with Vix: AUC = \" + str(auc1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5d4bab5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ad81a23b10>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, pred)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f016d",
   "metadata": {},
   "source": [
    "# Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "832bebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"polynomial\", PolynomialFeatures(1)),\n",
    "    (\"model\", GradientBoostingClassifier(random_state = 0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0653c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Grid Search\n",
    "lr_param_grid = [{'model__n_estimators': [1,  5,  10, 50, 100],\n",
    "                   \"model__learning_rate\": [ 1, 2],\n",
    "                   'model__max_depth': [1, 3, 5],\n",
    "                 'polynomial__degree': [1, 2]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f5844aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "lr_grid_search = GridSearchCV(estimator=pipe,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c0b615",
   "metadata": {},
   "source": [
    "## Gradient Boosting for Data with VIX and Cycle Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b3e12319",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_polynomial__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582759</td>\n",
       "      <td>0.565517</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.521178</td>\n",
       "      <td>0.055492</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.582759</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.607759</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593218</td>\n",
       "      <td>0.084143</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006426</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789655</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.803448</td>\n",
       "      <td>0.771552</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.814655</td>\n",
       "      <td>0.702716</td>\n",
       "      <td>0.093890</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027867</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.686207</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.651940</td>\n",
       "      <td>0.114633</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813793</td>\n",
       "      <td>0.868966</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.831897</td>\n",
       "      <td>0.866379</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.758060</td>\n",
       "      <td>0.103387</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.043287</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662069</td>\n",
       "      <td>0.662069</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.719828</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.788793</td>\n",
       "      <td>0.697457</td>\n",
       "      <td>0.115961</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.033082</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.886207</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.885287</td>\n",
       "      <td>0.107231</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.193443</td>\n",
       "      <td>0.014179</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686207</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.767241</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.731537</td>\n",
       "      <td>0.125244</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.072882</td>\n",
       "      <td>0.012791</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.886207</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.901638</td>\n",
       "      <td>0.115606</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.404339</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686207</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.767241</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.740876</td>\n",
       "      <td>0.132203</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.548276</td>\n",
       "      <td>0.665517</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.648132</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.504310</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.628448</td>\n",
       "      <td>0.095378</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993103</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.820690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.814655</td>\n",
       "      <td>0.918103</td>\n",
       "      <td>0.864440</td>\n",
       "      <td>0.092190</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.056967</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544828</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.681034</td>\n",
       "      <td>0.633621</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.749296</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.013539</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.993103</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>0.814655</td>\n",
       "      <td>0.912730</td>\n",
       "      <td>0.076522</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.113238</td>\n",
       "      <td>0.016911</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813793</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.824899</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.083744</td>\n",
       "      <td>0.017541</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.979397</td>\n",
       "      <td>0.019825</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.553931</td>\n",
       "      <td>0.031244</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.917241</td>\n",
       "      <td>0.875862</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934109</td>\n",
       "      <td>0.053622</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.115147</td>\n",
       "      <td>0.015215</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.986063</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.729132</td>\n",
       "      <td>0.062792</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933175</td>\n",
       "      <td>0.061243</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.641379</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.119740</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.020355</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.695330</td>\n",
       "      <td>0.099068</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.013194</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.893937</td>\n",
       "      <td>0.132147</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.088329</td>\n",
       "      <td>0.012098</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.720690</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.573276</td>\n",
       "      <td>0.767241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760014</td>\n",
       "      <td>0.122354</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.025430</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.945057</td>\n",
       "      <td>0.075896</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.176716</td>\n",
       "      <td>0.015817</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.910345</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.784483</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884023</td>\n",
       "      <td>0.074208</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.074404</td>\n",
       "      <td>0.012040</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924138</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.969483</td>\n",
       "      <td>0.024413</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.556326</td>\n",
       "      <td>0.073322</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.910345</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945647</td>\n",
       "      <td>0.057734</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.105421</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924138</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.969483</td>\n",
       "      <td>0.024413</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.587347</td>\n",
       "      <td>0.062390</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 1, 'model__max_depth'...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.910345</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945647</td>\n",
       "      <td>0.057734</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582759</td>\n",
       "      <td>0.565517</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.521178</td>\n",
       "      <td>0.055492</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.582759</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.607759</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593218</td>\n",
       "      <td>0.084143</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.623420</td>\n",
       "      <td>0.151164</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.026888</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.454167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.768966</td>\n",
       "      <td>0.486207</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.654813</td>\n",
       "      <td>0.115280</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820690</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>0.665517</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.594267</td>\n",
       "      <td>0.127779</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.039345</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.486207</td>\n",
       "      <td>0.537931</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.109925</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.032452</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820690</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>0.665517</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.594267</td>\n",
       "      <td>0.127779</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.192323</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427586</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.486207</td>\n",
       "      <td>0.531034</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.629382</td>\n",
       "      <td>0.138134</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.073210</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820690</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>0.665517</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.594267</td>\n",
       "      <td>0.127779</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.396740</td>\n",
       "      <td>0.024058</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427586</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.486207</td>\n",
       "      <td>0.531034</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.629382</td>\n",
       "      <td>0.138134</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.548276</td>\n",
       "      <td>0.665517</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.647716</td>\n",
       "      <td>0.078665</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.504310</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.628448</td>\n",
       "      <td>0.095378</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.455172</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.662615</td>\n",
       "      <td>0.221048</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.053715</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727586</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.409483</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.689282</td>\n",
       "      <td>0.180206</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.824138</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.883621</td>\n",
       "      <td>0.694813</td>\n",
       "      <td>0.236878</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.113744</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727586</td>\n",
       "      <td>0.737931</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.162443</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.063943</td>\n",
       "      <td>0.015965</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737931</td>\n",
       "      <td>0.593103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.883621</td>\n",
       "      <td>0.740560</td>\n",
       "      <td>0.219782</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.378868</td>\n",
       "      <td>0.131078</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834483</td>\n",
       "      <td>0.737931</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.749195</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.099825</td>\n",
       "      <td>0.033792</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.593103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.883621</td>\n",
       "      <td>0.742629</td>\n",
       "      <td>0.218586</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.536698</td>\n",
       "      <td>0.335966</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834483</td>\n",
       "      <td>0.737931</td>\n",
       "      <td>0.665517</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.748506</td>\n",
       "      <td>0.132420</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.658621</td>\n",
       "      <td>0.641379</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.812385</td>\n",
       "      <td>0.123256</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.017169</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.695330</td>\n",
       "      <td>0.099068</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.610345</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.862629</td>\n",
       "      <td>0.123034</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.083432</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679310</td>\n",
       "      <td>0.679310</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.745431</td>\n",
       "      <td>0.127193</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.897399</td>\n",
       "      <td>0.108161</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.161840</td>\n",
       "      <td>0.015669</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727586</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.676724</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.763333</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.040044</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.903707</td>\n",
       "      <td>0.106942</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.277202</td>\n",
       "      <td>0.094602</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.831034</td>\n",
       "      <td>0.780172</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.795129</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.057613</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.903707</td>\n",
       "      <td>0.106942</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.343000</td>\n",
       "      <td>0.173616</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__learning_rate': 2, 'model__max_depth'...</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.831034</td>\n",
       "      <td>0.780172</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.795129</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001732      0.000594         0.001214        0.000341   \n",
       "1        0.006493      0.002788         0.001561        0.000649   \n",
       "2        0.006426      0.002483         0.001572        0.000804   \n",
       "3        0.027867      0.009157         0.001565        0.001195   \n",
       "4        0.008089      0.002303         0.000951        0.000567   \n",
       "5        0.043287      0.007877         0.001126        0.000336   \n",
       "6        0.033082      0.004735         0.001001        0.000004   \n",
       "7        0.193443      0.014179         0.001606        0.000632   \n",
       "8        0.072882      0.012791         0.001255        0.000337   \n",
       "9        0.404339      0.027075         0.001357        0.000452   \n",
       "10       0.002687      0.000828         0.000997        0.000448   \n",
       "11       0.015085      0.004700         0.001652        0.001182   \n",
       "12       0.012433      0.004501         0.001606        0.000877   \n",
       "13       0.056967      0.012249         0.001458        0.000484   \n",
       "14       0.013539      0.000201         0.001041        0.000161   \n",
       "15       0.113238      0.016911         0.001659        0.000790   \n",
       "16       0.083744      0.017541         0.001161        0.000739   \n",
       "17       0.553931      0.031244         0.001276        0.000420   \n",
       "18       0.115147      0.015215         0.001657        0.000933   \n",
       "19       0.729132      0.062792         0.001417        0.000593   \n",
       "20       0.004736      0.002114         0.001220        0.000780   \n",
       "21       0.020355      0.005869         0.001581        0.000805   \n",
       "22       0.013194      0.003159         0.001458        0.000650   \n",
       "23       0.088329      0.012098         0.001407        0.000929   \n",
       "24       0.025430      0.007102         0.001844        0.000670   \n",
       "25       0.176716      0.015817         0.001613        0.000620   \n",
       "26       0.074404      0.012040         0.001297        0.000587   \n",
       "27       0.556326      0.073322         0.001317        0.000607   \n",
       "28       0.105421      0.027153         0.001362        0.000508   \n",
       "29       0.587347      0.062390         0.001469        0.000660   \n",
       "30       0.001931      0.001373         0.001533        0.000980   \n",
       "31       0.005503      0.000697         0.001104        0.000299   \n",
       "32       0.005203      0.001774         0.001289        0.000646   \n",
       "33       0.026888      0.007615         0.002057        0.000770   \n",
       "34       0.008999      0.003149         0.001020        0.000414   \n",
       "35       0.039345      0.006210         0.001412        0.000816   \n",
       "36       0.032452      0.004894         0.001218        0.000596   \n",
       "37       0.192323      0.010279         0.001480        0.000686   \n",
       "38       0.073210      0.010745         0.001246        0.000591   \n",
       "39       0.396740      0.024058         0.001318        0.000501   \n",
       "40       0.003155      0.001888         0.001571        0.000538   \n",
       "41       0.013813      0.003932         0.001264        0.000416   \n",
       "42       0.007982      0.001466         0.001054        0.000834   \n",
       "43       0.053715      0.005344         0.001163        0.000337   \n",
       "44       0.019048      0.005852         0.001565        0.000915   \n",
       "45       0.113744      0.014265         0.001369        0.000592   \n",
       "46       0.063943      0.015965         0.001086        0.000307   \n",
       "47       0.378868      0.131078         0.001361        0.000455   \n",
       "48       0.099825      0.033792         0.001205        0.000396   \n",
       "49       0.536698      0.335966         0.001446        0.000479   \n",
       "50       0.003122      0.000432         0.001084        0.000528   \n",
       "51       0.017169      0.002746         0.001408        0.000549   \n",
       "52       0.012054      0.004275         0.001060        0.000443   \n",
       "53       0.083432      0.003803         0.001394        0.000482   \n",
       "54       0.022801      0.005255         0.001267        0.000613   \n",
       "55       0.161840      0.015669         0.001792        0.000748   \n",
       "56       0.040044      0.010842         0.001226        0.000357   \n",
       "57       0.277202      0.094602         0.001301        0.000462   \n",
       "58       0.057613      0.012385         0.001489        0.000842   \n",
       "59       0.343000      0.173616         0.001297        0.000644   \n",
       "\n",
       "   param_model__learning_rate param_model__max_depth  \\\n",
       "0                           1                      1   \n",
       "1                           1                      1   \n",
       "2                           1                      1   \n",
       "3                           1                      1   \n",
       "4                           1                      1   \n",
       "5                           1                      1   \n",
       "6                           1                      1   \n",
       "7                           1                      1   \n",
       "8                           1                      1   \n",
       "9                           1                      1   \n",
       "10                          1                      3   \n",
       "11                          1                      3   \n",
       "12                          1                      3   \n",
       "13                          1                      3   \n",
       "14                          1                      3   \n",
       "15                          1                      3   \n",
       "16                          1                      3   \n",
       "17                          1                      3   \n",
       "18                          1                      3   \n",
       "19                          1                      3   \n",
       "20                          1                      5   \n",
       "21                          1                      5   \n",
       "22                          1                      5   \n",
       "23                          1                      5   \n",
       "24                          1                      5   \n",
       "25                          1                      5   \n",
       "26                          1                      5   \n",
       "27                          1                      5   \n",
       "28                          1                      5   \n",
       "29                          1                      5   \n",
       "30                          2                      1   \n",
       "31                          2                      1   \n",
       "32                          2                      1   \n",
       "33                          2                      1   \n",
       "34                          2                      1   \n",
       "35                          2                      1   \n",
       "36                          2                      1   \n",
       "37                          2                      1   \n",
       "38                          2                      1   \n",
       "39                          2                      1   \n",
       "40                          2                      3   \n",
       "41                          2                      3   \n",
       "42                          2                      3   \n",
       "43                          2                      3   \n",
       "44                          2                      3   \n",
       "45                          2                      3   \n",
       "46                          2                      3   \n",
       "47                          2                      3   \n",
       "48                          2                      3   \n",
       "49                          2                      3   \n",
       "50                          2                      5   \n",
       "51                          2                      5   \n",
       "52                          2                      5   \n",
       "53                          2                      5   \n",
       "54                          2                      5   \n",
       "55                          2                      5   \n",
       "56                          2                      5   \n",
       "57                          2                      5   \n",
       "58                          2                      5   \n",
       "59                          2                      5   \n",
       "\n",
       "   param_model__n_estimators param_polynomial__degree  \\\n",
       "0                          1                        1   \n",
       "1                          1                        2   \n",
       "2                          5                        1   \n",
       "3                          5                        2   \n",
       "4                         10                        1   \n",
       "5                         10                        2   \n",
       "6                         50                        1   \n",
       "7                         50                        2   \n",
       "8                        100                        1   \n",
       "9                        100                        2   \n",
       "10                         1                        1   \n",
       "11                         1                        2   \n",
       "12                         5                        1   \n",
       "13                         5                        2   \n",
       "14                        10                        1   \n",
       "15                        10                        2   \n",
       "16                        50                        1   \n",
       "17                        50                        2   \n",
       "18                       100                        1   \n",
       "19                       100                        2   \n",
       "20                         1                        1   \n",
       "21                         1                        2   \n",
       "22                         5                        1   \n",
       "23                         5                        2   \n",
       "24                        10                        1   \n",
       "25                        10                        2   \n",
       "26                        50                        1   \n",
       "27                        50                        2   \n",
       "28                       100                        1   \n",
       "29                       100                        2   \n",
       "30                         1                        1   \n",
       "31                         1                        2   \n",
       "32                         5                        1   \n",
       "33                         5                        2   \n",
       "34                        10                        1   \n",
       "35                        10                        2   \n",
       "36                        50                        1   \n",
       "37                        50                        2   \n",
       "38                       100                        1   \n",
       "39                       100                        2   \n",
       "40                         1                        1   \n",
       "41                         1                        2   \n",
       "42                         5                        1   \n",
       "43                         5                        2   \n",
       "44                        10                        1   \n",
       "45                        10                        2   \n",
       "46                        50                        1   \n",
       "47                        50                        2   \n",
       "48                       100                        1   \n",
       "49                       100                        2   \n",
       "50                         1                        1   \n",
       "51                         1                        2   \n",
       "52                         5                        1   \n",
       "53                         5                        2   \n",
       "54                        10                        1   \n",
       "55                        10                        2   \n",
       "56                        50                        1   \n",
       "57                        50                        2   \n",
       "58                       100                        1   \n",
       "59                       100                        2   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "0   {'model__learning_rate': 1, 'model__max_depth'...           0.483333  ...   \n",
       "1   {'model__learning_rate': 1, 'model__max_depth'...           0.466667  ...   \n",
       "2   {'model__learning_rate': 1, 'model__max_depth'...           0.537500  ...   \n",
       "3   {'model__learning_rate': 1, 'model__max_depth'...           0.429167  ...   \n",
       "4   {'model__learning_rate': 1, 'model__max_depth'...           0.558333  ...   \n",
       "5   {'model__learning_rate': 1, 'model__max_depth'...           0.641667  ...   \n",
       "6   {'model__learning_rate': 1, 'model__max_depth'...           0.650000  ...   \n",
       "7   {'model__learning_rate': 1, 'model__max_depth'...           0.833333  ...   \n",
       "8   {'model__learning_rate': 1, 'model__max_depth'...           0.650000  ...   \n",
       "9   {'model__learning_rate': 1, 'model__max_depth'...           0.875000  ...   \n",
       "10  {'model__learning_rate': 1, 'model__max_depth'...           0.525000  ...   \n",
       "11  {'model__learning_rate': 1, 'model__max_depth'...           0.450000  ...   \n",
       "12  {'model__learning_rate': 1, 'model__max_depth'...           0.812500  ...   \n",
       "13  {'model__learning_rate': 1, 'model__max_depth'...           0.758333  ...   \n",
       "14  {'model__learning_rate': 1, 'model__max_depth'...           0.870833  ...   \n",
       "15  {'model__learning_rate': 1, 'model__max_depth'...           0.941667  ...   \n",
       "16  {'model__learning_rate': 1, 'model__max_depth'...           0.941667  ...   \n",
       "17  {'model__learning_rate': 1, 'model__max_depth'...           0.875000  ...   \n",
       "18  {'model__learning_rate': 1, 'model__max_depth'...           0.958333  ...   \n",
       "19  {'model__learning_rate': 1, 'model__max_depth'...           0.866667  ...   \n",
       "20  {'model__learning_rate': 1, 'model__max_depth'...           0.641667  ...   \n",
       "21  {'model__learning_rate': 1, 'model__max_depth'...           0.704167  ...   \n",
       "22  {'model__learning_rate': 1, 'model__max_depth'...           0.741667  ...   \n",
       "23  {'model__learning_rate': 1, 'model__max_depth'...           0.883333  ...   \n",
       "24  {'model__learning_rate': 1, 'model__max_depth'...           0.866667  ...   \n",
       "25  {'model__learning_rate': 1, 'model__max_depth'...           0.854167  ...   \n",
       "26  {'model__learning_rate': 1, 'model__max_depth'...           0.933333  ...   \n",
       "27  {'model__learning_rate': 1, 'model__max_depth'...           0.866667  ...   \n",
       "28  {'model__learning_rate': 1, 'model__max_depth'...           0.933333  ...   \n",
       "29  {'model__learning_rate': 1, 'model__max_depth'...           0.866667  ...   \n",
       "30  {'model__learning_rate': 2, 'model__max_depth'...           0.483333  ...   \n",
       "31  {'model__learning_rate': 2, 'model__max_depth'...           0.466667  ...   \n",
       "32  {'model__learning_rate': 2, 'model__max_depth'...           0.558333  ...   \n",
       "33  {'model__learning_rate': 2, 'model__max_depth'...           0.454167  ...   \n",
       "34  {'model__learning_rate': 2, 'model__max_depth'...           0.670833  ...   \n",
       "35  {'model__learning_rate': 2, 'model__max_depth'...           0.754167  ...   \n",
       "36  {'model__learning_rate': 2, 'model__max_depth'...           0.670833  ...   \n",
       "37  {'model__learning_rate': 2, 'model__max_depth'...           0.754167  ...   \n",
       "38  {'model__learning_rate': 2, 'model__max_depth'...           0.670833  ...   \n",
       "39  {'model__learning_rate': 2, 'model__max_depth'...           0.754167  ...   \n",
       "40  {'model__learning_rate': 2, 'model__max_depth'...           0.520833  ...   \n",
       "41  {'model__learning_rate': 2, 'model__max_depth'...           0.450000  ...   \n",
       "42  {'model__learning_rate': 2, 'model__max_depth'...           0.908333  ...   \n",
       "43  {'model__learning_rate': 2, 'model__max_depth'...           0.766667  ...   \n",
       "44  {'model__learning_rate': 2, 'model__max_depth'...           0.916667  ...   \n",
       "45  {'model__learning_rate': 2, 'model__max_depth'...           0.766667  ...   \n",
       "46  {'model__learning_rate': 2, 'model__max_depth'...           0.850000  ...   \n",
       "47  {'model__learning_rate': 2, 'model__max_depth'...           0.766667  ...   \n",
       "48  {'model__learning_rate': 2, 'model__max_depth'...           0.850000  ...   \n",
       "49  {'model__learning_rate': 2, 'model__max_depth'...           0.766667  ...   \n",
       "50  {'model__learning_rate': 2, 'model__max_depth'...           0.629167  ...   \n",
       "51  {'model__learning_rate': 2, 'model__max_depth'...           0.704167  ...   \n",
       "52  {'model__learning_rate': 2, 'model__max_depth'...           0.725000  ...   \n",
       "53  {'model__learning_rate': 2, 'model__max_depth'...           0.666667  ...   \n",
       "54  {'model__learning_rate': 2, 'model__max_depth'...           0.691667  ...   \n",
       "55  {'model__learning_rate': 2, 'model__max_depth'...           0.700000  ...   \n",
       "56  {'model__learning_rate': 2, 'model__max_depth'...           0.683333  ...   \n",
       "57  {'model__learning_rate': 2, 'model__max_depth'...           0.850000  ...   \n",
       "58  {'model__learning_rate': 2, 'model__max_depth'...           0.683333  ...   \n",
       "59  {'model__learning_rate': 2, 'model__max_depth'...           0.850000  ...   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0            0.582759           0.565517           0.479310   \n",
       "1            0.600000           0.600000           0.582759   \n",
       "2            0.789655           0.724138           0.637931   \n",
       "3            0.689655           0.775862           0.686207   \n",
       "4            0.813793           0.868966           0.682759   \n",
       "5            0.662069           0.662069           0.772414   \n",
       "6            0.972414           0.886207           0.710345   \n",
       "7            0.686207           0.717241           0.751724   \n",
       "8            0.986207           0.886207           0.710345   \n",
       "9            0.686207           0.751724           0.751724   \n",
       "10           0.748276           0.548276           0.665517   \n",
       "11           0.710345           0.672414           0.682759   \n",
       "12           0.993103           0.772414           0.820690   \n",
       "13           0.544828           0.786207           0.644828   \n",
       "14           0.979310           0.786207           0.972414   \n",
       "15           0.813793           0.758621           0.655172   \n",
       "16           1.000000           0.979310           0.979310   \n",
       "17           0.979310           0.917241           0.875862   \n",
       "18           1.000000           1.000000           0.979310   \n",
       "19           0.979310           0.951724           0.827586   \n",
       "20           0.979310           0.672414           0.641379   \n",
       "21           0.696552           0.751724           0.672414   \n",
       "22           1.000000           0.586207           0.979310   \n",
       "23           0.600000           0.696552           0.720690   \n",
       "24           1.000000           0.744828           0.979310   \n",
       "25           0.965517           0.841379           0.910345   \n",
       "26           1.000000           0.924138           0.979310   \n",
       "27           0.979310           0.951724           0.910345   \n",
       "28           1.000000           0.924138           0.979310   \n",
       "29           0.979310           0.951724           0.910345   \n",
       "30           0.582759           0.565517           0.479310   \n",
       "31           0.600000           0.600000           0.582759   \n",
       "32           0.793103           0.496552           0.479310   \n",
       "33           0.689655           0.768966           0.486207   \n",
       "34           0.820690           0.379310           0.479310   \n",
       "35           0.696552           0.844828           0.486207   \n",
       "36           0.820690           0.379310           0.479310   \n",
       "37           0.427586           0.844828           0.486207   \n",
       "38           0.820690           0.379310           0.479310   \n",
       "39           0.427586           0.844828           0.486207   \n",
       "40           0.748276           0.548276           0.665517   \n",
       "41           0.710345           0.672414           0.682759   \n",
       "42           1.000000           0.717241           0.455172   \n",
       "43           0.727586           0.734483           0.696552   \n",
       "44           1.000000           0.696552           0.465517   \n",
       "45           0.727586           0.737931           0.710345   \n",
       "46           1.000000           0.737931           0.593103   \n",
       "47           0.834483           0.737931           0.672414   \n",
       "48           1.000000           0.731034           0.593103   \n",
       "49           0.834483           0.737931           0.665517   \n",
       "50           0.979310           0.658621           0.641379   \n",
       "51           0.696552           0.751724           0.672414   \n",
       "52           1.000000           0.610345           0.786207   \n",
       "53           0.679310           0.679310           0.734483   \n",
       "54           1.000000           0.748276           0.979310   \n",
       "55           0.727586           0.696552           0.734483   \n",
       "56           1.000000           0.775862           0.979310   \n",
       "57           0.717241           0.693103           0.734483   \n",
       "58           1.000000           0.775862           0.979310   \n",
       "59           0.717241           0.693103           0.734483   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0            0.500000           0.500000           0.538793   \n",
       "1            0.500000           0.625000           0.607759   \n",
       "2            0.803448           0.771552           0.741379   \n",
       "3            0.448276           0.625000           0.711207   \n",
       "4            0.827586           0.831897           0.866379   \n",
       "5            0.465517           0.719828           0.931034   \n",
       "6            0.965517           0.896552           0.956897   \n",
       "7            0.465517           0.767241           0.965517   \n",
       "8            0.986207           0.956897           0.974138   \n",
       "9            0.465517           0.767241           0.982759   \n",
       "10           0.693103           0.741379           0.663793   \n",
       "11           0.517241           0.625000           0.504310   \n",
       "12           1.000000           0.793103           0.814655   \n",
       "13           0.710345           0.681034           0.633621   \n",
       "14           0.993103           0.991379           0.849138   \n",
       "15           0.724138           0.706897           0.887931   \n",
       "16           1.000000           1.000000           0.982759   \n",
       "17           0.958621           0.939655           0.982759   \n",
       "18           1.000000           1.000000           0.982759   \n",
       "19           0.951724           0.948276           0.982759   \n",
       "20           0.862069           0.793103           0.810345   \n",
       "21           0.696552           0.586207           0.482759   \n",
       "22           0.986207           0.793103           0.965517   \n",
       "23           0.744828           0.573276           0.767241   \n",
       "24           0.986207           0.991379           0.956897   \n",
       "25           0.882759           0.784483           0.982759   \n",
       "26           0.986207           0.982759           0.956897   \n",
       "27           0.986207           0.982759           1.000000   \n",
       "28           0.986207           0.982759           0.956897   \n",
       "29           0.986207           0.982759           1.000000   \n",
       "30           0.500000           0.500000           0.538793   \n",
       "31           0.500000           0.625000           0.607759   \n",
       "32           0.696552           0.663793           0.534483   \n",
       "33           0.627586           0.625000           0.758621   \n",
       "34           0.665517           0.663793           0.534483   \n",
       "35           0.537931           0.625000           0.732759   \n",
       "36           0.665517           0.663793           0.534483   \n",
       "37           0.531034           0.689655           0.491379   \n",
       "38           0.665517           0.663793           0.534483   \n",
       "39           0.531034           0.689655           0.491379   \n",
       "40           0.693103           0.741379           0.663793   \n",
       "41           0.517241           0.625000           0.504310   \n",
       "42           0.862069           0.387931           0.741379   \n",
       "43           0.762069           0.327586           0.409483   \n",
       "44           0.824138           0.465517           0.922414   \n",
       "45           0.644828           0.327586           0.637931   \n",
       "46           1.000000           0.517241           0.905172   \n",
       "47           0.644828           0.517241           0.732759   \n",
       "48           1.000000           0.517241           0.905172   \n",
       "49           0.644828           0.517241           0.732759   \n",
       "50           0.862069           0.793103           0.810345   \n",
       "51           0.696552           0.586207           0.482759   \n",
       "52           0.944828           0.793103           0.956897   \n",
       "53           0.779310           0.612069           0.965517   \n",
       "54           0.986207           0.793103           0.965517   \n",
       "55           0.772414           0.676724           0.974138   \n",
       "56           0.986207           0.793103           0.965517   \n",
       "57           0.831034           0.780172           0.982759   \n",
       "58           0.986207           0.793103           0.965517   \n",
       "59           0.831034           0.780172           0.982759   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.431034         0.521178        0.055492               59  \n",
       "1            0.500000         0.593218        0.084143               57  \n",
       "2            0.814655         0.702716        0.093890               37  \n",
       "3            0.758621         0.651940        0.114633               46  \n",
       "4            0.754310         0.758060        0.103387               27  \n",
       "5            0.788793         0.697457        0.115961               38  \n",
       "6            0.931034         0.885287        0.107231               16  \n",
       "7            0.797414         0.731537        0.125244               35  \n",
       "8            0.974138         0.901638        0.115606               13  \n",
       "9            0.797414         0.740876        0.132203               33  \n",
       "10           0.551724         0.648132        0.078000               47  \n",
       "11           0.732759         0.628448        0.095378               51  \n",
       "12           0.918103         0.864440        0.092190               18  \n",
       "13           0.974138         0.749296        0.126750               28  \n",
       "14           0.814655         0.912730        0.076522               10  \n",
       "15           0.982759         0.824899        0.109478               20  \n",
       "16           0.982759         0.979397        0.019825                2  \n",
       "17           1.000000         0.934109        0.053622                8  \n",
       "18           0.991379         0.986063        0.014354                1  \n",
       "19           1.000000         0.933175        0.061243                9  \n",
       "20           0.879310         0.815014        0.119740               21  \n",
       "21           0.732759         0.695330        0.099068               39  \n",
       "22           0.948276         0.893937        0.132147               15  \n",
       "23           1.000000         0.760014        0.122354               26  \n",
       "24           0.965517         0.945057        0.075896                7  \n",
       "25           1.000000         0.884023        0.074208               17  \n",
       "26           0.965517         0.969483        0.024413                3  \n",
       "27           1.000000         0.945647        0.057734                5  \n",
       "28           0.965517         0.969483        0.024413                3  \n",
       "29           1.000000         0.945647        0.057734                5  \n",
       "30           0.431034         0.521178        0.055492               59  \n",
       "31           0.500000         0.593218        0.084143               57  \n",
       "32           0.431034         0.623420        0.151164               53  \n",
       "33           0.758621         0.654813        0.115280               45  \n",
       "34           0.431034         0.594267        0.127779               54  \n",
       "35           0.689655         0.674641        0.109925               43  \n",
       "36           0.431034         0.594267        0.127779               54  \n",
       "37           0.689655         0.629382        0.138134               49  \n",
       "38           0.431034         0.594267        0.127779               54  \n",
       "39           0.689655         0.629382        0.138134               49  \n",
       "40           0.551724         0.647716        0.078665               48  \n",
       "41           0.732759         0.628448        0.095378               51  \n",
       "42           0.663793         0.662615        0.221048               44  \n",
       "43           0.974138         0.689282        0.180206               42  \n",
       "44           0.883621         0.694813        0.236878               41  \n",
       "45           0.974138         0.708333        0.162443               36  \n",
       "46           0.883621         0.740560        0.219782               34  \n",
       "47           0.974138         0.749195        0.132003               29  \n",
       "48           0.883621         0.742629        0.218586               32  \n",
       "49           0.974138         0.748506        0.132420               30  \n",
       "50           0.879310         0.812385        0.123256               22  \n",
       "51           0.732759         0.695330        0.099068               39  \n",
       "52           0.870690         0.862629        0.123034               19  \n",
       "53           0.991379         0.745431        0.127193               31  \n",
       "54           0.870690         0.897399        0.108161               14  \n",
       "55           0.991379         0.763333        0.117800               25  \n",
       "56           0.896552         0.903707        0.106942               11  \n",
       "57           0.991379         0.795129        0.115361               23  \n",
       "58           0.896552         0.903707        0.106942               11  \n",
       "59           0.991379         0.795129        0.115361               23  \n",
       "\n",
       "[60 rows x 22 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid_search.fit(x_train, y_train)\n",
    "df = pd.DataFrame(lr_grid_search.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8f554c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"polynomial\", PolynomialFeatures(1)),\n",
    "    (\"model\", GradientBoostingClassifier(learning_rate = 1, max_depth = 3, n_estimators = 100, random_state = 0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "97b7bf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ad84d7eb50>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5yklEQVR4nO3deVyVZf7/8fdhOSwG5IoLiFquOWVi5pKZZZBa2lQjpbmUNfkzMzUrzR5uU9lqtqk1uTQzaFZq+Z0clUZRUlugQ6Y42rhmQKQVGJgKXL8//HK+HjkgB5Ur8PV8PO7HQ+5z3ff9uS+O3O9z3ctxGGOMAAAALPGzXQAAALiwEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWBVgu4CKKC4uVmZmpsLCwuRwOGyXAwAAKsAYoyNHjqhx48by8yt7/KNahJHMzExFR0fbLgMAAFTCd999p6ioqDJfrxZhJCwsTNLJnQkPD7dcDQAAqIi8vDxFR0e7j+NlqRZhpOTUTHh4OGEEAIBq5kyXWHABKwAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALDK5zCyceNG3XLLLWrcuLEcDoc+/PDDMy6zYcMGxcbGKjg4WC1atNC8efMqUysAAKiBfA4j+fn5uuKKK/T6669XqP3evXvVt29f9ejRQy6XS0888YTGjBmjZcuW+VwsAACoeXz+bpo+ffqoT58+FW4/b948NW3aVLNnz5YktW3bVqmpqXrxxRd1++23+7p5nMIYo6MnimyXAQCoAUIC/c/4HTLny3n/orwtW7YoLi7OY158fLzmz5+vEydOKDAwsNQyx44d07Fjx9w/5+Xlne8yqx1jjO6Yt0Vp+3+2XQoAoAbImBGvUKed78897xewZmdnKzIy0mNeZGSkCgsLdejQIa/LzJw5UxEREe4pOjr6fJdZ7Rw9UUQQAQDUCFUSgU4f9jHGeJ1fYtKkSRo/frz757y8PAJJOVKf7K1Qp7/tMgAA1VhIoL3jyHkPIw0bNlR2drbHvJycHAUEBKhu3bpelwkKClJQUND5Lq3GCHX6WxtaAwDgbJ330zRdu3ZVUlKSx7y1a9eqU6dOXq8XAQAAFxafw8ivv/6q9PR0paenSzp56256eroOHDgg6eQplqFDh7rbjxw5Uvv379f48eO1Y8cOLViwQPPnz9eECRPOzR4AAIBqzeex/dTUVPXq1cv9c8m1HcOGDdOiRYuUlZXlDiaS1Lx5c61atUrjxo3TG2+8ocaNG+vVV1/ltl4AACCpEmHkuuuuc1+A6s2iRYtKzevZs6e++uorXzcFAAAuAHw3DQAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACs4hniFWSM0dETRbbLcCs4/vupBQCAs0EYqQBjjO6Yt4VvyQUA4DzgNE0FHD1R9LsNIp1ialv9pkUAAM4WIyM+Sn2yt0Kdv5+Df0igvxwOh+0yAACoNMKIj0Kd/gp10m0AAJwrnKYBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYFWC7gN8TY4yOnigqNb/geOl5AADg3CCM/C9jjO6Yt0Vp+3+2XQoAABcUTtP8r6Mnis4YRDrF1FZIoH8VVQQAwIWBkREvUp/srVBn6dAREugvh8NhoSIAAGouwogXoU5/hTrpGgAAqgKnaQAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVZUKI3PmzFHz5s0VHBys2NhYpaSklNs+MTFRV1xxhUJDQ9WoUSPdc889Onz4cKUKBgAANYvPYWTp0qUaO3asJk+eLJfLpR49eqhPnz46cOCA1/affvqphg4dqhEjRmj79u16//339eWXX+q+++476+IBAED153MYmTVrlkaMGKH77rtPbdu21ezZsxUdHa25c+d6bf/ZZ5+pWbNmGjNmjJo3b65rrrlGDzzwgFJTU8+6eAAAUP35FEaOHz+utLQ0xcXFecyPi4vT5s2bvS7TrVs3HTx4UKtWrZIxRj/88IM++OAD9evXr8ztHDt2THl5eR4TAAComXwKI4cOHVJRUZEiIyM95kdGRio7O9vrMt26dVNiYqISEhLkdDrVsGFDXXzxxXrttdfK3M7MmTMVERHhnqKjo30pEwAAVCOVuoDV4XB4/GyMKTWvREZGhsaMGaMpU6YoLS1Nq1ev1t69ezVy5Mgy1z9p0iTl5ua6p++++64yZQIAgGogwJfG9erVk7+/f6lRkJycnFKjJSVmzpyp7t2769FHH5UkXX755apVq5Z69Oihp556So0aNSq1TFBQkIKCgnwpDQAAVFM+jYw4nU7FxsYqKSnJY35SUpK6devmdZmCggL5+Xluxt/fX9LJERUAAHBh8/k0zfjx4/X2229rwYIF2rFjh8aNG6cDBw64T7tMmjRJQ4cOdbe/5ZZbtHz5cs2dO1d79uzRpk2bNGbMGHXu3FmNGzc+d3sCAACqJZ9O00hSQkKCDh8+rBkzZigrK0vt27fXqlWrFBMTI0nKysryeObI8OHDdeTIEb3++ut65JFHdPHFF+v666/Xc889d+72AgAAVFsOUw3OleTl5SkiIkK5ubkKDw8/L9soOF6odlPWSJIyZsQr1OlzTgMAAKeo6PGb76YBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWFWpMDJnzhw1b95cwcHBio2NVUpKSrntjx07psmTJysmJkZBQUG65JJLtGDBgkoVDAAAapYAXxdYunSpxo4dqzlz5qh79+5688031adPH2VkZKhp06Zelxk4cKB++OEHzZ8/X5deeqlycnJUWFh41sUDAIDqz+cwMmvWLI0YMUL33XefJGn27Nlas2aN5s6dq5kzZ5Zqv3r1am3YsEF79uxRnTp1JEnNmjU7u6oBAECN4dNpmuPHjystLU1xcXEe8+Pi4rR582avy6xcuVKdOnXS888/ryZNmqhVq1aaMGGCjh49WuZ2jh07pry8PI8JAADUTD6NjBw6dEhFRUWKjIz0mB8ZGans7Gyvy+zZs0effvqpgoODtWLFCh06dEijRo3STz/9VOZ1IzNnztT06dN9KQ0AAFRTlbqA1eFwePxsjCk1r0RxcbEcDocSExPVuXNn9e3bV7NmzdKiRYvKHB2ZNGmScnNz3dN3331XmTIBAEA14NPISL169eTv719qFCQnJ6fUaEmJRo0aqUmTJoqIiHDPa9u2rYwxOnjwoFq2bFlqmaCgIAUFBflSGgAAqKZ8GhlxOp2KjY1VUlKSx/ykpCR169bN6zLdu3dXZmamfv31V/e8Xbt2yc/PT1FRUZUoGQAA1CQ+n6YZP3683n77bS1YsEA7duzQuHHjdODAAY0cOVLSyVMsQ4cOdbcfNGiQ6tatq3vuuUcZGRnauHGjHn30Ud17770KCQk5d3sCAACqJZ9v7U1ISNDhw4c1Y8YMZWVlqX379lq1apViYmIkSVlZWTpw4IC7/UUXXaSkpCQ99NBD6tSpk+rWrauBAwfqqaeeOnd7AQAAqi2HMcbYLuJM8vLyFBERodzcXIWHh5+XbRQcL1S7KWskSRkz4hXq9DmnAQCAU1T0+M130wAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsCrBdgE3GGB09USRJKjheZLkaAAAuTBdsGDHG6I55W5S2/2fbpQAAcEG7YE/THD1R5DWIdIqprZBAfwsVAQBwYbpgR0ZOlfpkb4U6TwaQkEB/ORwOyxUBAHDhIIxICnX6K9RJVwAAYMMFe5oGAAD8PhBGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGBVpcLInDlz1Lx5cwUHBys2NlYpKSkVWm7Tpk0KCAhQhw4dKrNZAABQA/kcRpYuXaqxY8dq8uTJcrlc6tGjh/r06aMDBw6Uu1xubq6GDh2qG264odLFAgCAmsfnMDJr1iyNGDFC9913n9q2bavZs2crOjpac+fOLXe5Bx54QIMGDVLXrl0rXSwAAKh5fAojx48fV1pamuLi4jzmx8XFafPmzWUut3DhQu3evVtTp06t0HaOHTumvLw8jwkAANRMPoWRQ4cOqaioSJGRkR7zIyMjlZ2d7XWZb7/9VhMnTlRiYqICAgIqtJ2ZM2cqIiLCPUVHR/tSJgAAqEYqdQGrw+Hw+NkYU2qeJBUVFWnQoEGaPn26WrVqVeH1T5o0Sbm5ue7pu+++q0yZAACgGqjYUMX/qlevnvz9/UuNguTk5JQaLZGkI0eOKDU1VS6XS6NHj5YkFRcXyxijgIAArV27Vtdff32p5YKCghQUFORLaQAAoJryaWTE6XQqNjZWSUlJHvOTkpLUrVu3Uu3Dw8P1zTffKD093T2NHDlSrVu3Vnp6uq6++uqzqx4AAFR7Po2MSNL48eM1ZMgQderUSV27dtVbb72lAwcOaOTIkZJOnmL5/vvv9be//U1+fn5q3769x/INGjRQcHBwqfkAAODC5HMYSUhI0OHDhzVjxgxlZWWpffv2WrVqlWJiYiRJWVlZZ3zmCAAAQAmHMcbYLuJM8vLyFBERodzcXIWHh5+TdRYcL1S7KWskSRkz4hXq9DmXAQCAclT0+M130wAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsqlQYmTNnjpo3b67g4GDFxsYqJSWlzLbLly/XjTfeqPr16ys8PFxdu3bVmjVrKl0wAACoWXwOI0uXLtXYsWM1efJkuVwu9ejRQ3369NGBAwe8tt+4caNuvPFGrVq1SmlpaerVq5duueUWuVyusy4eAABUfw5jjPFlgauvvlodO3bU3Llz3fPatm2rW2+9VTNnzqzQOi677DIlJCRoypQpFWqfl5eniIgI5ebmKjw83Jdyy1RwvFDtppwcocmYEa9QZ8A5WS8AADiposdvn0ZGjh8/rrS0NMXFxXnMj4uL0+bNmyu0juLiYh05ckR16tQps82xY8eUl5fnMQEAgJrJpzBy6NAhFRUVKTIy0mN+ZGSksrOzK7SOl156Sfn5+Ro4cGCZbWbOnKmIiAj3FB0d7UuZAACgGqnUBawOh8PjZ2NMqXneLFmyRNOmTdPSpUvVoEGDMttNmjRJubm57um7776rTJkAAKAa8OlCiXr16snf37/UKEhOTk6p0ZLTLV26VCNGjND777+v3r17l9s2KChIQUFBvpQGAACqKZ9GRpxOp2JjY5WUlOQxPykpSd26dStzuSVLlmj48OFavHix+vXrV7lKAQBAjeTzLSTjx4/XkCFD1KlTJ3Xt2lVvvfWWDhw4oJEjR0o6eYrl+++/19/+9jdJJ4PI0KFD9corr6hLly7uUZWQkBBFREScw10BAADVkc9hJCEhQYcPH9aMGTOUlZWl9u3ba9WqVYqJiZEkZWVleTxz5M0331RhYaEefPBBPfjgg+75w4YN06JFi85+DwAAQLXm83NGbOA5IwAAVD/n5TkjAAAA5xphBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVAbYLqE6Kiop04sQJ22UAAPC7EBgYKH9//7NeD2GkAowxys7O1i+//GK7FAAAflcuvvhiNWzYUA6Ho9LrIIxUQEkQadCggUJDQ8+qwwEAqAmMMSooKFBOTo4kqVGjRpVeF2HkDIqKitxBpG7durbLAQDgdyMkJESSlJOTowYNGlT6lA0XsJ5ByTUioaGhlisBAOD3p+T4eDbXVBJGKohTMwAAlHYujo+EEQAAYBVhBGelWbNmmj17dqWXX7RokS6++OJzVk9Nct1112ns2LG2y/BQ0d+Xw+HQhx9+eM63P3z4cN16663nfL0A7CKM1GBV8Yf7yy+/1J///OcKtfUWXBISErRr165Kb3/RokVyOBzuKTIyUrfccou2b99e6XX+Xixfvlx/+ctfbJfh4fTf17Rp09ShQ4ezXu8f/vAH3XfffV5fW7JkiQIDA/XDDz/olVde0aJFi856e94cPXpUtWvXVp06dXT06NFSr5cVsMaOHavrrrvOY152drYeeughtWjRQkFBQYqOjtYtt9yif//73+el9hIbNmxQbGysgoOD1aJFC82bN++My/z73/9Wt27dFBYWpkaNGunxxx9XYWGhR5v33ntPHTp0UGhoqGJiYvTCCy9UatvLli1Tu3btFBQUpHbt2mnFihUer8+cOVNXXXWVwsLC1KBBA916663auXOnR5vly5crPj5e9erVk8PhUHp6eqntPPDAA7rkkksUEhKi+vXra8CAAfrPf/7j0WbXrl0aMGCA6tWrp/DwcHXv3l3r1693v/7111/rrrvuUnR0tEJCQtS2bVu98sorHuuYNm2ax9+fkqlWrVruNsnJyV7bnFrP9u3bdfvtt6tZs2ZyOBxeP+BVpG9O74PT17Vv3z6vtTgcDr3//vvudv3791fTpk0VHBysRo0aaciQIcrMzCxzW+cCYQRnpX79+md1cW9ISIgaNGhwVjWEh4crKytLmZmZ+vjjj5Wfn69+/frp+PHjZ7XeMznfD8CrU6eOwsLCzus2fHUufl/ejBgxQu+9954KCgpKvbZgwQLdfPPNioyMVERExHkbSVu2bJnat2+vdu3aafny5ZVez759+xQbG6t169bp+eef1zfffKPVq1erV69eevDBB89hxZ727t2rvn37qkePHnK5XHriiSc0ZswYLVu2rMxltm7dqr59++qmm26Sy+XSu+++q5UrV2rixInuNv/61780ePBgjRw5Utu2bdOcOXM0a9Ysvf766z5te8uWLUpISNCQIUP09ddfa8iQIRo4cKA+//xzd5sNGzbowQcf1GeffaakpCQVFhYqLi5O+fn57jb5+fnq3r27nn322TL3KzY2VgsXLtSOHTu0Zs0aGWMUFxenoqIid5t+/fqpsLBQ69atU1pamjp06KCbb75Z2dnZkqS0tDTVr19f//jHP7R9+3ZNnjxZkyZN8tjvCRMmKCsry2Nq166d/vSnP5WqaefOnR7tWrZs6X6toKBALVq00LPPPquGDRt63aeK9E2JDz/8UJ9//rkaN27sMT86OrpUvdOnT1etWrXUp08fd7tevXrpvffe086dO7Vs2TLt3r1bd9xxR5n9fU6YaiA3N9dIMrm5uedsnfnHTpiYx/9pYh7/p8k/dqLMdkePHjUZGRnm6NGj52zbVWXYsGFmwIABZb6enJxsrrrqKuN0Ok3Dhg3N448/bk6c+L++yMvLM4MGDTKhoaGmYcOGZtasWaZnz57m4YcfdreJiYkxL7/8svvnqVOnmujoaON0Ok2jRo3MQw89ZIwxpmfPnkaSx2SMMQsXLjQREREedX300UcmNjbWBAUFmbp165o//vGPZe6Dt+VXrlxpJJmtW7e6523atMn06NHDBAcHm6ioKPPQQw+ZX3/91f16Zmam6du3rwkODjbNmjUziYmJpfZNkpk7d67p37+/CQ0NNVOmTHFvr2PHjiYoKMg0b97cTJs2zaMfy+oTY4x54403zKWXXmqCgoJMgwYNzO233+5+7fS+/umnn8yQIUPMxRdfbEJCQsxNN91kdu3aVaovVq9ebdq0aWNq1apl4uPjTWZmZpn9t3LlShMREWGKioqMMca4XC4jyUyYMMHd5s9//rO58847S/X3woULS/1OFy5c6O6rv/71r+bWW281ISEh5tJLLzUfffRRmXUcOnTIOJ1Os2jRIo/5+/fvN35+fuZ//ud/jDGe7+mcnBwTGRlpnn76aXf7zz77zAQGBpo1a9aUua2yXHfddWbevHlm7ty5plevXqVel2RWrFhRav7DDz9sevbs6f65T58+pkmTJh7vrxI///yzz3VV1GOPPWbatGnjMe+BBx4wXbp0KXOZSZMmmU6dOnnMW7FihQkODjZ5eXnGGGPuuusuc8cdd3i0efnll01UVJQpLi6u8LYHDhxobrrpJo828fHx7veWNzk5OUaS2bBhQ6nX9u7dayQZl8tV5vIlvv76ayPJ/Pe//zXGGPPjjz8aSWbjxo3uNnl5eUaS+eSTT8pcz6hRo7y+N0qkp6eXWu/69euNpAr/7k//u1OWsvrm4MGDpkmTJmbbtm0VWleHDh3MvffeW26bjz76yDgcDnP8+HGvr5d3nKzo8ZuRkUowxqjgeKGVyRhzTvbh+++/V9++fXXVVVfp66+/1ty5czV//nw99dRT7jbjx4/Xpk2btHLlSiUlJSklJUVfffVVmev84IMP9PLLL+vNN9/Ut99+qw8//FB/+MMfJJ0cWo2KitKMGTPcidybjz/+WLfddpv69esnl8ulf//73+rUqVOF9+uXX37R4sWLJZ18TLEkffPNN4qPj9dtt92mrVu3aunSpfr00081evRo93JDhw5VZmamkpOTtWzZMr311lvuB/mcaurUqRowYIC++eYb3XvvvVqzZo3uvvtujRkzRhkZGXrzzTe1aNEiPf3002fsk9TUVI0ZM0YzZszQzp07tXr1al177bVl7tvw4cOVmpqqlStXasuWLTLGqG/fvh4jNAUFBXrxxRf197//XRs3btSBAwc0YcKEMtd57bXX6siRI3K5XJJOfvqqV6+eNmzY4G6TnJysnj17llo2ISFBjzzyiC677DL37zQhIcH9+vTp0zVw4ED3p+/Bgwfrp59+8lpH3bp1NWDAAC1cuNBj/sKFCxUZGenxqa1E/fr1tWDBAk2bNk2pqan69ddfdffdd2vUqFGKi4uT9H/D0snJyWX2gSTt3r1bW7Zs0cCBAzVw4EBt3rxZe/bsKXcZb3766SetXr1aDz74oMdQfYnyRnUSExN10UUXlTslJiaWufyWLVvc+10iPj5eqampZY7iHTt2TMHBwR7zQkJC9NtvvyktLa3cNgcPHtT+/fsrvO2y2mzevLnMfcrNzZV0cpSwsvLz87Vw4UI1b95c0dHRkk6+39q2bau//e1vys/PV2Fhod58801FRkYqNja23HrKq+Xtt99Wq1at1KNHj1KvXXnllWrUqJFuuOEGj9NBleWtb4qLizVkyBA9+uijuuyyy864jrS0NKWnp2vEiBFltvnpp5+UmJiobt26uf+mng+VeujZnDlz9MILLygrK0uXXXaZZs+e7bXzS2zYsEHjx4/X9u3b1bhxYz322GMaOXJkpYu27eiJIrWbssbKtjNmxCvUefbPqpszZ46io6P1+uuvy+FwqE2bNsrMzNTjjz+uKVOmKD8/X++8844WL16sG264QdLJA8Ppw36nOnDggBo2bKjevXsrMDBQTZs2VefOnSWd/A/j7++vsLCwMochJenpp5/WnXfeqenTp7vnXXHFFeXuS25uri666CL30wClk+c827RpI0l64YUXNGjQIPfFoC1bttSrr76qnj17au7cudq3b58++eQTffnll+7g8/bbb3sMo5YYNGiQ7r33XvfPQ4YM0cSJEzVs2DBJUosWLfSXv/xFjz32mKZOnVpunxw4cEC1atXSzTffrLCwMMXExOjKK6/0uo/ffvutVq5cqU2bNqlbt26STh68oqOj9eGHH7qHhU+cOKF58+bpkksukSSNHj1aM2bMKLPvIiIi1KFDByUnJys2NlbJyckaN26cpk+friNHjig/P1+7du0qdU2EdPKAdNFFFykgIMDr73T48OG66667JEnPPPOMXnvtNX3xxRe66aabvNZy7733qm/fvtqzZ49atGghY4wWLVqk4cOHl/kgpb59++r+++/X4MGDddVVVyk4ONhj+D4wMFCtW7c+46nEBQsWqE+fPqpdu7Yk6aabbtKCBQs8wnlF/Pe//5Uxxv3e80X//v119dVXl9smMjKyzNeys7NLvR4ZGanCwkIdOnTI69Mx4+PjNXv2bC1ZskQDBw5Udna2e59LPjDEx8dr3LhxGj58uHr16qX//ve/7usQsrKy1KxZswptu6w2JadFTmeM0fjx43XNNdeoffv25faLN3PmzNFjjz2m/Px8tWnTRklJSXI6nZJOXv+TlJSkAQMGKCwsTH5+foqMjNTq1avLDIxbtmzRe++9p48//tjr68eOHVNiYqLHKS7p5FNJ33rrLcXGxurYsWP6+9//rhtuuEHJycnlfvgoT1l989xzzykgIEBjxoyp0Hrmz5+vtm3buv+mnOrxxx/X66+/roKCAnXp0kX//Oc/K1VrRfk8MrJ06VKNHTtWkydPlsvlUo8ePdSnTx8dOHDAa/vKnMfE+bdjxw517drV4/7w7t2769dff9XBgwe1Z88enThxwn3glE4euFq3bl3mOv/0pz/p6NGjatGihe6//36tWLGi1IVwZ5Kenu4OPxUVFham9PR0paWluQ/Ep148l5aWpkWLFnl8woyPj1dxcbH27t2rnTt3KiAgQB07dnQvc+mll7oPTKc6fZQmLS1NM2bM8Fj3/fffr6ysLBUUFJTbJzfeeKNiYmLUokULDRkyRImJiV6vmZBO/r4CAgI8DlZ169ZV69attWPHDve80NBQdxCRTv4hLBnhSUlJ8fop+7rrrlNycrKMMUpJSdGAAQPUvn17ffrpp1q/fr0iIyMrdXC9/PLL3f+uVauWwsLCvI42lYiLi1NUVJR7dGTdunXat2+f7rnnnnK38+KLL6qwsFDvvfeeEhMTPT7FN2nSRP/5z3883senKyoq0jvvvKO7777bPe/uu+/WO++843GNQUWUjFxW5rkLYWFhuvTSS8udznQN0enbPVM9cXFxeuGFFzRy5EgFBQWpVatW6tevnyS5A+D999+v0aNH6+abb5bT6VSXLl105513erSp6La9tSmrttGjR2vr1q1asmRJuftclsGDB8vlcmnDhg1q2bKlBg4cqN9++8293VGjRqlBgwZKSUnRF198oQEDBujmm2/2Omq7fft2DRgwQFOmTNGNN97odXvLly/XkSNHNHToUI/5rVu31v3336+OHTuqa9eumjNnjvr166cXX3yxUvslee+btLQ09wXeFXn/HT16VIsXLy5zVOTRRx+Vy+XS2rVr5e/vr6FDh56zkXlvfP6IPWvWLI0YMcJ95fvs2bO1Zs0azZ07VzNnzizVft68eWratKk7Sbdt21apqal68cUXdfvtt59d9ZaEBPorY0a8tW2fC97+CJz6x6OsP2LlvRmjo6O1c+dOJSUl6ZNPPtGoUaP0wgsvaMOGDRUe3it5tLAv/Pz8dOmll0qS2rRpo+zsbCUkJGjjxo2STg5dPvDAA14/LTRt2rTMK9K97evpQ+/FxcWaPn26brvttlJtg4ODy+2TsLAwffXVV0pOTtbatWs1ZcoUTZs2TV9++WWpT2dl9fvpv8fT+/nU32WnTp087jwo+ZR63XXXaf78+fr666/l5+endu3aqWfPntqwYYN+/vlnr6doKsJbLcXFxWW29/Pz0/Dhw7Vo0SJNnz5dCxcu1LXXXut1hOpUe/bsUWZmpoqLi7V//36PEFQRa9as0ffff+9xikk6GVLWrl3rPkUUFhbmHho/1S+//KKIiAhJJ0fdHA6HduzY4fOdbImJiXrggQfKbfPmm29q8ODBXl9r2LBhqVGGnJwcBQQElPtVFuPHj9e4ceOUlZWl2rVra9++fZo0aZKaN28u6eTv7bnnntMzzzyj7Oxs1a9f331XULNmzSq87bLaeBvteeihh7Ry5Upt3LhRUVFR5fRI2SIiIhQREaGWLVuqS5cuql27tlasWKG77rpL69at0z//+U/9/PPPCg8Pl3RyJCUpKUnvvPOOx+hGRkaGrr/+et1///168skny9ze22+/rZtvvrnckd8SXbp00T/+8Y9K7VdZfZOSkqKcnBw1bdrUPa+oqEiPPPKIZs+erX379nms54MPPlBBQUGp8FSiXr16qlevnlq1aqW2bdsqOjpan332mbp27Vqpus/Ep5GR48ePKy0trdR5v7i4uDLP+1X2PGZeXp7H9HvicDgU6gywMp2rJ8G2a9dOmzdv9jjIbd68WWFhYWrSpIkuueQSBQYG6osvvnC/npeXp2+//bbc9YaEhKh///569dVXlZycrC1btuibb76RJDmdzjN+0rz88svP+vbHcePG6euvv3bfNtixY0dt377d6ydNp9OpNm3aqLCw0H3dhHRyuL0i39LcsWNH7dy50+u6/fxO/vcqr08CAgLUu3dvPf/889q6dav27dundevWldpOu3btVFhY6HHnweHDh7Vr1y61bdu2Qv0SEhLi9VN2yXUjs2fPVs+ePeVwONSzZ08lJyeXeb1IiYr8Tn1xzz336ODBg1q+fLmWL19e7rls6eTfpMGDByshIUFPPfWURowYoR9++MGnbc6fP1933nmn0tPTPabBgwdr/vz57nZt2rTRl19+6bGsMUZpaWnuEcM6deooPj5eb7zxhte7HMp7T/Xv379UDadP/fv3L3P5rl27KikpyWPe2rVr1alTpzN+GHA4HGrcuLFCQkK0ZMkSRUdHe4wUSidHQZo0aSKn06klS5aoa9eu7jurKrLtstqceorAGKPRo0dr+fLlWrdunTsQnQvGGB07dkyS3COQJf9HS/j5+XkE5u3bt6tXr14aNmyY+zowb/bu3av169ef8f1awuVy+fylcmfqmyFDhmjr1q0e75fGjRvr0Ucf1Zo1pS8rmD9/vvr376/69etXaNuS3P13XpR7eetpvv/+eyPJbNq0yWP+008/bVq1auV1mZYtW3pc7W7MyTsbJJV5lf/UqVNLXaUv7qbx2bBhw8x1111nXC6Xx7R//35z8OBBExoaah588EGzY8cO8+GHH5p69eqZqVOnupe/7777TPPmzc26devMtm3bzO23327CwsLM2LFj3W1OvVp74cKF5u233zbffPON2b17t5k8ebIJCQkxhw4dMsYYc+ONN5r+/fubgwcPmh9//NG9zKl3w6xfv974+fmZKVOmmIyMDLN161bz3HPPlbmP3u6mMcaY8ePHmz/84Q+muLjYfP311yYkJMSMGjXKuFwus2vXLvPRRx+Z0aNHu9v37t3bdOzY0Xz++efmq6++Mr169TIhISFm9uzZ7jbycjfF6tWrTUBAgJk6darZtm2bycjIMO+++66ZPHnyGfvkf/7nf8wrr7xiXC6X2bdvn5kzZ47x8/Mz27ZtM8aUvptmwIABpl27diYlJcWkp6ebm266yVx66aXuK9y99cWKFStMRf6bd+zY0fj7+5vXX3/dGHPyzp3AwEAjyWzfvr3M/k5MTDS1atUyLpfL/Pjjj+a3334rs68iIiLcd9uU54YbbjC1a9c24eHhJj8/3+O10+8QmzBhgmnWrJnJzc01RUVF5tprrzX9+vVzv37w4EHTunVr8/nnn3vdVk5OjgkMDDT/+te/Sr22du1aExgYaHJycowxxixdutQEBweb1157zezcudOkp6ebUaNGmZCQELNv3z73cnv27DENGzY07dq1Mx988IHZtWuXycjIMK+88kqpO07OpT179pjQ0FAzbtw4k5GRYebPn28CAwPNBx984G6zfPly07p1a4/lnn/+ebN161azbds2M2PGDBMYGOjxu/vxxx/N3LlzzY4dO4zL5TJjxowxwcHBHn1akW1v2rTJ+Pv7m2effdbs2LHDPPvssyYgIMB89tln7jb/7//9PxMREWGSk5NNVlaWeyooKHC3OXz4sHG5XObjjz82ksy7775rXC6XycrKMsYYs3v3bvPMM8+Y1NRUs3//frN582YzYMAAU6dOHfPDDz+496lu3brmtttuM+np6Wbnzp1mwoQJJjAw0KSnpxtjjNm2bZupX7++GTx4sEctJe+HUz355JOmcePGprCwsNRrL7/8slmxYoXZtWuX2bZtm5k4caKRZJYtW+Zuc+zYMfff50aNGpkJEyYYl8tlvv32W5/65nRl3U3z7bffGofD4fV9//nnn5vXXnvN/Xdp3bp15pprrjGXXHKJ+//36c7F3TSVCiObN2/2mP/UU0+VeoOXaNmypXnmmWc85n366adGkvvNc7rffvvN5ObmuqfvvvvunIeR4uJik3/shMk/dsJ9e5o31T2MeAt1w4YNM8ZU7tbezp07m4kTJ7rbnPpmX7Fihbn66qtNeHi4qVWrlunSpYvHbXJbtmwxl19+uQkKCir31t5ly5aZDh06GKfTaerVq2duu+22MvexrDCyf/9+ExAQYJYuXWqMMeaLL74wN954o7noootMrVq1zOWXX+4RkjMzM02fPn1MUFCQiYmJMYsXLzYNGjQw8+bNc7fxdoA15mQg6datmwkJCTHh4eGmc+fO5q233jpjn6SkpJiePXua2rVrm5CQEHP55Ze76zWm7Ft7IyIiTEhIiImPj/d6a++pKhpGHnnkESPJHYSMMeaKK64w9evX9/j/cfo2fvvtN3P77bebiy++uNStvZUNI4sXLzaSzJ///OdSr50aRtavX28CAgJMSkqK+/X9+/ebiIgIM2fOHGPM/93+uX79eq/bevHFF83FF1/s9ZbFEydOmDp16piXXnrJPe/dd981nTp1MuHh4aZBgwYmPj7epKamllo2MzPTPPjggyYmJsY4nU7TpEkT079//zLrOFeSk5PNlVdeaZxOp2nWrJmZO3eux+slt2OfqlevXiYiIsIEBwebq6++2qxatcrj9R9//NF06dLF1KpVy4SGhpobbrjBI0BUdNvGGPP++++b1q1bm8DAQNOmTRuPA7Ixxuvfq1PfV6fuw+lTyQep77//3vTp08c0aNDABAYGmqioKDNo0CDzn//8x2NbX375pYmLizN16tQxYWFhpkuXLh77XtaH4piYGI/1FBUVmaioKPPEE0+U2l9jjHnuuefMJZdcYoKDg03t2rXNNddcYz7++GOPNiXv09OnU28Zr0jfnK6sMDJp0iQTFRXlvqX/VFu3bjW9evUyderUMUFBQaZZs2Zm5MiR5uDBg2Vu51yEEcf/7mSFHD9+XKGhoXr//ff1xz/+0T3/4YcfVnp6usftgCWuvfZaXXnllR5PrluxYoUGDhyogoKCCl1LkJeXp4iICOXm5rrP71WV3377TXv37lXz5s1L3d52ocnPz1eTJk300ksvVXg4sro6ePCgoqOj9cknn/h8QS0AXEjKO05W9Pjt0zUjTqdTsbGxpc77JSUleb01SDq785iwy+VyacmSJdq9e7e++uor94VzAwYMsFzZubdu3TqtXLlSe/fu1ebNm3XnnXeqWbNmlb71DgBQcT7f2jt+/Hi9/fbbWrBggXbs2KFx48bpwIED7ueGTJo0yePq3JEjR2r//v0aP368duzYoQULFmj+/PnlPogJvx8vvviirrjiCvXu3Vv5+flKSUlRvXr1bJd1zp04cUJPPPGELrvsMv3xj39U/fr1lZycTGAGgCrg8629CQkJOnz4sPtJmu3bt9eqVasUExMj6eRDcE595kjz5s21atUqjRs3Tm+88YYaN26sV199tdre1nshufLKK91PYazp4uPjFR9v53ZtALjQ+XTNiC1cMwIAwO9TlV8zAgAAcK4RRiqovCdHAgBwoToXx8ez/8a1Gs7pdMrPz0+ZmZmqX7++nE7nOXsKKgAA1ZUxRsePH9ePP/4oPz8/9xcRVgZh5Az8/PzUvHlzZWVlKTMz03Y5AAD8roSGhqpp06alHq/vC8JIBTidTjVt2lSFhYXn9Hs4AACozvz9/RUQcPbfm0YYqSCHw6HAwECeOwEAwDnGBawAAMAqwggAALCKMAIAAKyqFteMlDwkNi8vz3IlAACgokqO22d62Hu1CCNHjhyRJEVHR1uuBAAA+OrIkSOKiIgo8/Vq8d00xcXFyszMVFhY2Dl94FheXp6io6P13XffVfl33lxo6OuqQT9XDfq5atDPVeN89rMxRkeOHFHjxo3LfQ5JtRgZ8fPzU1RU1Hlbf3h4OG/0KkJfVw36uWrQz1WDfq4a56ufyxsRKcEFrAAAwCrCCAAAsOqCDiNBQUGaOnWqgoKCbJdS49HXVYN+rhr0c9Wgn6vG76Gfq8UFrAAAoOa6oEdGAACAfYQRAABgFWEEAABYRRgBAABW1fgwMmfOHDVv3lzBwcGKjY1VSkpKue03bNig2NhYBQcHq0WLFpo3b14VVVq9+dLPy5cv14033qj69esrPDxcXbt21Zo1a6qw2urN1/d0iU2bNikgIEAdOnQ4vwXWEL7287FjxzR58mTFxMQoKChIl1xyiRYsWFBF1VZfvvZzYmKirrjiCoWGhqpRo0a65557dPjw4SqqtnrauHGjbrnlFjVu3FgOh0MffvjhGZep8mOhqcHeffddExgYaP7617+ajIwM8/DDD5tatWqZ/fv3e22/Z88eExoaah5++GGTkZFh/vrXv5rAwEDzwQcfVHHl1Yuv/fzwww+b5557znzxxRdm165dZtKkSSYwMNB89dVXVVx59eNrX5f45ZdfTIsWLUxcXJy54oorqqbYaqwy/dy/f39z9dVXm6SkJLN3717z+eefm02bNlVh1dWPr/2ckpJi/Pz8zCuvvGL27NljUlJSzGWXXWZuvfXWKq68elm1apWZPHmyWbZsmZFkVqxYUW57G8fCGh1GOnfubEaOHOkxr02bNmbixIle2z/22GOmTZs2HvMeeOAB06VLl/NWY03gaz97065dOzN9+vRzXVqNU9m+TkhIME8++aSZOnUqYaQCfO3nf/3rXyYiIsIcPny4KsqrMXzt5xdeeMG0aNHCY96rr75qoqKizluNNU1FwoiNY2GNPU1z/PhxpaWlKS4uzmN+XFycNm/e7HWZLVu2lGofHx+v1NRUnThx4rzVWp1Vpp9PV1xcrCNHjqhOnTrno8Qao7J9vXDhQu3evVtTp0493yXWCJXp55UrV6pTp056/vnn1aRJE7Vq1UoTJkzQ0aNHq6Lkaqky/dytWzcdPHhQq1atkjFGP/zwgz744AP169evKkq+YNg4FlaLL8qrjEOHDqmoqEiRkZEe8yMjI5Wdne11mezsbK/tCwsLdejQITVq1Oi81VtdVaafT/fSSy8pPz9fAwcOPB8l1hiV6etvv/1WEydOVEpKigICaux/93OqMv28Z88effrppwoODtaKFSt06NAhjRo1Sj/99BPXjZShMv3crVs3JSYmKiEhQb/99psKCwvVv39/vfbaa1VR8gXDxrGwxo6MlHA4HB4/G2NKzTtTe2/z4cnXfi6xZMkSTZs2TUuXLlWDBg3OV3k1SkX7uqioSIMGDdL06dPVqlWrqiqvxvDlPV1cXCyHw6HExER17txZffv21axZs7Ro0SJGR87Al37OyMjQmDFjNGXKFKWlpWn16tXau3evRo4cWRWlXlCq+lhYYz8q1atXT/7+/qUSdk5OTqnEV6Jhw4Ze2wcEBKhu3brnrdbqrDL9XGLp0qUaMWKE3n//ffXu3ft8llkj+NrXR44cUWpqqlwul0aPHi3p5EHTGKOAgACtXbtW119/fZXUXp1U5j3dqFEjNWnSxOOr0tu2bStjjA4ePKiWLVue15qro8r088yZM9W9e3c9+uijkqTLL79ctWrVUo8ePfTUU08xen2O2DgW1tiREafTqdjYWCUlJXnMT0pKUrdu3bwu07Vr11Lt165dq06dOikwMPC81VqdVaafpZMjIsOHD9fixYs531tBvvZ1eHi4vvnmG6Wnp7unkSNHqnXr1kpPT9fVV19dVaVXK5V5T3fv3l2ZmZn69ddf3fN27dolPz8/RUVFndd6q6vK9HNBQYH8/DwPW/7+/pL+75M7zp6VY+F5uzT2d6DktrH58+ebjIwMM3bsWFOrVi2zb98+Y4wxEydONEOGDHG3L7mdady4cSYjI8PMnz+fW3srwNd+Xrx4sQkICDBvvPGGycrKck+//PKLrV2oNnzt69NxN03F+NrPR44cMVFRUeaOO+4w27dvNxs2bDAtW7Y09913n61dqBZ87eeFCxeagIAAM2fOHLN7927z6aefmk6dOpnOnTvb2oVq4ciRI8blchmXy2UkmVmzZhmXy+W+hfr3cCys0WHEGGPeeOMNExMTY5xOp+nYsaPZsGGD+7Vhw4aZnj17erRPTk42V155pXE6naZZs2Zm7ty5VVxx9eRLP/fs2dNIKjUNGzas6guvhnx9T5+KMFJxvvbzjh07TO/evU1ISIiJiooy48ePNwUFBVVcdfXjaz+/+uqrpl27diYkJMQ0atTIDB482Bw8eLCKq65e1q9fX+7f3N/DsdBhDGNbAADAnhp7zQgAAKgeCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACs+v+Op1/DNJESwQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob = gbm_pipe.fit(x_train, y_train).predict_proba(x_test)\n",
    "pred = gbm_pipe.fit(x_train, y_train).predict(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob[:, 1], pos_label=1)\n",
    "auc1 = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label = \"Logistic Regression-with Vix: AUC = \" + str(auc1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "647b1abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ad83b42650>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, pred)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d65b2c",
   "metadata": {},
   "source": [
    "## Gradient Boosting for Data without VIX and Cycle Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "debb1f85",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[278], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lr_grid_search\u001b[38;5;241m.\u001b[39mfit(x_train_vix, y_train_vix)\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(lr_grid_search\u001b[38;5;241m.\u001b[39mcv_results_)\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[0;32m    539\u001b[0m     X,\n\u001b[0;32m    540\u001b[0m     y,\n\u001b[0;32m    541\u001b[0m     raw_predictions,\n\u001b[0;32m    542\u001b[0m     sample_weight,\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[0;32m    544\u001b[0m     X_val,\n\u001b[0;32m    545\u001b[0m     y_val,\n\u001b[0;32m    546\u001b[0m     sample_weight_val,\n\u001b[0;32m    547\u001b[0m     begin_at_stage,\n\u001b[0;32m    548\u001b[0m     monitor,\n\u001b[0;32m    549\u001b[0m )\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[0;32m    616\u001b[0m     i,\n\u001b[0;32m    617\u001b[0m     X,\n\u001b[0;32m    618\u001b[0m     y,\n\u001b[0;32m    619\u001b[0m     raw_predictions,\n\u001b[0;32m    620\u001b[0m     sample_weight,\n\u001b[0;32m    621\u001b[0m     sample_mask,\n\u001b[0;32m    622\u001b[0m     random_state,\n\u001b[0;32m    623\u001b[0m     X_csc,\n\u001b[0;32m    624\u001b[0m     X_csr,\n\u001b[0;32m    625\u001b[0m )\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    254\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    256\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 257\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(X, residual, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    260\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    261\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_grid_search.fit(x_train_vix, y_train_vix)\n",
    "df = pd.DataFrame(lr_grid_search.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "43371fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"polynomial\", PolynomialFeatures(1)),\n",
    "    (\"model\", GradientBoostingClassifier(learning_rate = 1, max_depth = 3, n_estimators = 100, random_state = 0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "6c572801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ad84e1fa90>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob = gbm_pipe.fit(x_train_vix, y_train_vix).predict_proba(x_test_vix)\n",
    "pred = gbm_pipe.fit(x_train_vix, y_train_vix).predict(x_test_vix)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob[:, 1], pos_label=1)\n",
    "auc1 = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label = \"Logistic Regression-with Vix: AUC = \" + str(auc1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "8502d93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ad81f8d7d0>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, pred)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
